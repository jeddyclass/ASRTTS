{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cc30973-a7a9-4b5f-932d-cd0dd63318ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-whisper in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (20240930)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numba in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (from openai-whisper) (0.61.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (from openai-whisper) (2.2.6)\n",
      "Requirement already satisfied: torch in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (from openai-whisper) (2.7.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (from openai-whisper) (4.67.1)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (from openai-whisper) (10.7.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (from openai-whisper) (0.9.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (from numba->openai-whisper) (0.44.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.4.26)\n",
      "Requirement already satisfied: filelock in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (from torch->openai-whisper) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (from torch->openai-whisper) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (from torch->openai-whisper) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (from torch->openai-whisper) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (from torch->openai-whisper) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (from torch->openai-whisper) (2025.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages (from tqdm->openai-whisper) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install -U openai-whisper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb3e4f6f-bb08-40b0-bbe3-20bd1b480084",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPU\n",
    "## pip install torch torchvision torchaudio\n",
    "## For CUDA 11.8 (adjust depending on your system):\n",
    "##pip install --index-url https://download.pytorch.org/whl/cu118 torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3fd0554-dcf4-42c4-ba15-0fc13c8f8c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.1.1-full_build-www.gyan.dev Copyright (c) 2000-2025 the FFmpeg developers\n",
      "built with gcc 14.2.0 (Rev1, Built by MSYS2 project)\n",
      "configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-lcms2 --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-libdvdnav --enable-libdvdread --enable-sdl2 --enable-libaribb24 --enable-libaribcaption --enable-libdav1d --enable-libdavs2 --enable-libopenjpeg --enable-libquirc --enable-libuavs3d --enable-libxevd --enable-libzvbi --enable-libqrencode --enable-librav1e --enable-libsvtav1 --enable-libvvenc --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxeve --enable-libxvid --enable-libaom --enable-libjxl --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libcodec2 --enable-libilbc --enable-libgsm --enable-liblc3 --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\n",
      "libavutil      59. 39.100 / 59. 39.100\n",
      "libavcodec     61. 19.101 / 61. 19.101\n",
      "libavformat    61.  7.100 / 61.  7.100\n",
      "libavdevice    61.  3.100 / 61.  3.100\n",
      "libavfilter    10.  4.100 / 10.  4.100\n",
      "libswscale      8.  3.100 /  8.  3.100\n",
      "libswresample   5.  3.100 /  5.  3.100\n",
      "libpostproc    58.  3.100 / 58.  3.100\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb9be1f-94d1-4728-b392-0e118af84c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\950207\\anaconda3\\envs\\gptcode\\lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription:\n",
      " 拜一種禮物出現另外一種禮物出現整個方式它是用這個車延網產業的一個一個產業店的方式用上週下\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import torch\n",
    "\n",
    "def transcribe_audio(audio_path='output.wav', use_gpu=True):\n",
    "    \"\"\"\n",
    "    Transcribe an audio file using Whisper.\n",
    "    \n",
    "    Parameters:\n",
    "        audio_path (str): WAV file name (must be in the same directory).\n",
    "        use_gpu (bool): If True, use GPU; else use CPU.\n",
    "\n",
    "    Returns:\n",
    "        dict: Whisper result containing 'text', 'segments', etc.\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    try:\n",
    "        model = whisper.load_model(\"base\", device=device)\n",
    "        result = model.transcribe(audio_path)\n",
    "        print(\"Transcription:\\n\", result[\"text\"])\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(\"Error during transcription:\", e)\n",
    "\n",
    "# Example: change use_gpu to True if you want GPU\n",
    "result = transcribe_audio(\"output.wav\", use_gpu=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fc7bc1-ecbf-48c2-b517-8b89a9821025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
