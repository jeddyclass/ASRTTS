{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copyright: GPT_SoVITS_DeanLin"
      ],
      "metadata": {
        "id": "O1UcvBWF_CXK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtOtTFiGZJ-N"
      },
      "source": [
        "## 0. 初始化檢查"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maUJ4mNpYxxQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e52524a0-0412-4030-8479-b2d7b78bfb01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default GPU Device Details: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "if tf.test.gpu_device_name():\n",
        "    print('Default GPU Device Details: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIgovmIrZVAc"
      },
      "source": [
        " ## 1. 掛載到 Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMytosXDZUMg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a9b4b0e-b881-423f-e9f9-6822d191ff81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66ri0484Yz64"
      },
      "source": [
        "## 2. Clone GitHub 最新程式，並下載對應的環境"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rGL8TjVsjUD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "214f5cdf-1c0b-4642-b2de-6b85becc9510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'GPT-SoVITS' already exists and is not an empty directory.\n",
            "/content/GPT-SoVITS\n",
            "Cloning into 'GPT_SoVITS/pretrained_models'...\n",
            "remote: Enumerating objects: 69, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 69 (delta 12), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (69/69), 115.92 KiB | 3.31 MiB/s, done.\n",
            "Filtering content: 100% (19/19), 4.93 GiB | 26.76 MiB/s, done.\n",
            "Ignoring onnxruntime: markers 'platform_machine == \"aarch64\" or platform_machine == \"arm64\"' don't match your environment\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.15.3)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.18.0)\n",
            "Requirement already satisfied: librosa==0.10.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.10.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.60.0)\n",
            "Requirement already satisfied: pytorch-lightning>=2.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.5.1.post0)\n",
            "Requirement already satisfied: gradio<5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.44.1)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: onnxruntime-gpu in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (1.22.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (4.67.1)\n",
            "Requirement already satisfied: funasr==1.0.27 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (1.0.27)\n",
            "Requirement already satisfied: cn2an in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (0.5.23)\n",
            "Requirement already satisfied: pypinyin in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (0.54.0)\n",
            "Requirement already satisfied: pyopenjtalk>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (0.4.1)\n",
            "Requirement already satisfied: g2p_en in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (2.1.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (2.6.0+cu124)\n",
            "Requirement already satisfied: modelscope==1.10.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (1.10.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (0.2.0)\n",
            "Requirement already satisfied: transformers<=4.50,>=4.43 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (4.50.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (0.15.2)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 23)) (5.2.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 24)) (6.0.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 25)) (5.9.5)\n",
            "Requirement already satisfied: jieba_fast in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 26)) (0.53)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (0.42.1)\n",
            "Requirement already satisfied: split-lang in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (2.1.0)\n",
            "Requirement already satisfied: fast_langdetect>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 29)) (0.3.2)\n",
            "Requirement already satisfied: wordsegment in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 30)) (1.3.1)\n",
            "Requirement already satisfied: rotary_embedding_torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 31)) (0.8.6)\n",
            "Requirement already satisfied: ToJyutping in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 32)) (3.2.0)\n",
            "Requirement already satisfied: g2pk2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 33)) (0.0.3)\n",
            "Requirement already satisfied: ko_pron in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 34)) (1.3)\n",
            "Requirement already satisfied: opencc in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 35)) (1.1.9)\n",
            "Requirement already satisfied: python_mecab_ko in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 36)) (1.3.7)\n",
            "Requirement already satisfied: fastapi>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.2->-r requirements.txt (line 37)) (0.115.12)\n",
            "Requirement already satisfied: x_transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 38)) (2.3.12)\n",
            "Requirement already satisfied: torchmetrics<=1.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 39)) (1.5.0)\n",
            "Requirement already satisfied: pydantic<=2.10.6 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 40)) (2.10.6)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 41)) (4.6.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.13 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 42)) (0.32.4)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 43)) (0.21.1)\n",
            "Requirement already satisfied: av>=11 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 44)) (14.4.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.2->-r requirements.txt (line 5)) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.2->-r requirements.txt (line 5)) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.2->-r requirements.txt (line 5)) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.2->-r requirements.txt (line 5)) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.2->-r requirements.txt (line 5)) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.2->-r requirements.txt (line 5)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.2->-r requirements.txt (line 5)) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.2->-r requirements.txt (line 5)) (4.14.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.2->-r requirements.txt (line 5)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.2->-r requirements.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: jamo in /usr/local/lib/python3.11/dist-packages (from funasr==1.0.27->-r requirements.txt (line 13)) (0.4.1)\n",
            "Requirement already satisfied: kaldiio>=2.17.0 in /usr/local/lib/python3.11/dist-packages (from funasr==1.0.27->-r requirements.txt (line 13)) (2.18.1)\n",
            "Requirement already satisfied: torch-complex in /usr/local/lib/python3.11/dist-packages (from funasr==1.0.27->-r requirements.txt (line 13)) (0.4.4)\n",
            "Requirement already satisfied: pytorch-wpe in /usr/local/lib/python3.11/dist-packages (from funasr==1.0.27->-r requirements.txt (line 13)) (0.0.1)\n",
            "Requirement already satisfied: editdistance>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from funasr==1.0.27->-r requirements.txt (line 13)) (0.8.1)\n",
            "Requirement already satisfied: oss2 in /usr/local/lib/python3.11/dist-packages (from funasr==1.0.27->-r requirements.txt (line 13)) (2.19.1)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.11/dist-packages (from funasr==1.0.27->-r requirements.txt (line 13)) (0.5.7)\n",
            "Requirement already satisfied: jaconv in /usr/local/lib/python3.11/dist-packages (from funasr==1.0.27->-r requirements.txt (line 13)) (0.4.0)\n",
            "Requirement already satisfied: hydra-core>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from funasr==1.0.27->-r requirements.txt (line 13)) (1.3.2)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.11/dist-packages (from funasr==1.0.27->-r requirements.txt (line 13)) (2.6.4)\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.11/dist-packages (from funasr==1.0.27->-r requirements.txt (line 13)) (20240930)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 19)) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 19)) (25.3.0)\n",
            "Requirement already satisfied: datasets>=2.14.5 in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 19)) (3.6.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 19)) (0.8.1)\n",
            "Requirement already satisfied: filelock>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 19)) (3.18.0)\n",
            "Requirement already satisfied: gast>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 19)) (0.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 19)) (2.2.2)\n",
            "Requirement already satisfied: Pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 19)) (10.4.0)\n",
            "Requirement already satisfied: pyarrow!=9.0.0,>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 19)) (18.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 19)) (2.9.0.post0)\n",
            "Requirement already satisfied: requests>=2.25 in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 19)) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 19)) (75.2.0)\n",
            "Requirement already satisfied: simplejson>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 19)) (3.20.1)\n",
            "Requirement already satisfied: sortedcontainers>=1.5.9 in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 19)) (2.4.0)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 19)) (2.4.0)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 19)) (0.43.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 4)) (1.72.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 4)) (3.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 4)) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 4)) (5.29.5)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 4)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 4)) (3.1.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->-r requirements.txt (line 6)) (0.43.0)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=2.4->-r requirements.txt (line 7)) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (2025.3.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=2.4->-r requirements.txt (line 7)) (0.14.3)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio<5->-r requirements.txt (line 8)) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<5->-r requirements.txt (line 8)) (4.9.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio<5->-r requirements.txt (line 8)) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<5->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio<5->-r requirements.txt (line 8)) (0.28.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio<5->-r requirements.txt (line 8)) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<5->-r requirements.txt (line 8)) (3.1.6)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<5->-r requirements.txt (line 8)) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<5->-r requirements.txt (line 8)) (3.10.0)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<5->-r requirements.txt (line 8)) (3.10.18)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio<5->-r requirements.txt (line 8)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from gradio<5->-r requirements.txt (line 8)) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio<5->-r requirements.txt (line 8)) (0.11.12)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<5->-r requirements.txt (line 8)) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio<5->-r requirements.txt (line 8)) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio<5->-r requirements.txt (line 8)) (0.16.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio<5->-r requirements.txt (line 8)) (0.34.3)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.3.0->gradio<5->-r requirements.txt (line 8)) (12.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python->-r requirements.txt (line 9)) (1.0.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu->-r requirements.txt (line 11)) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu->-r requirements.txt (line 11)) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu->-r requirements.txt (line 11)) (1.13.1)\n",
            "Requirement already satisfied: proces>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from cn2an->-r requirements.txt (line 14)) (0.1.7)\n",
            "Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.11/dist-packages (from g2p_en->-r requirements.txt (line 17)) (3.9.1)\n",
            "Requirement already satisfied: inflect>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from g2p_en->-r requirements.txt (line 17)) (7.5.0)\n",
            "Requirement already satisfied: distance>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from g2p_en->-r requirements.txt (line 17)) (0.1.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime-gpu->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<=4.50,>=4.43->-r requirements.txt (line 21)) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<=4.50,>=4.43->-r requirements.txt (line 21)) (0.5.3)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft->-r requirements.txt (line 22)) (1.7.0)\n",
            "Requirement already satisfied: budoux in /usr/local/lib/python3.11/dist-packages (from split-lang->-r requirements.txt (line 28)) (0.7.0)\n",
            "Requirement already satisfied: robust-downloader>=0.0.2 in /usr/local/lib/python3.11/dist-packages (from fast_langdetect>=0.3.1->-r requirements.txt (line 29)) (0.0.2)\n",
            "Requirement already satisfied: fasttext-predict>=0.9.2.4 in /usr/local/lib/python3.11/dist-packages (from fast_langdetect>=0.3.1->-r requirements.txt (line 29)) (0.9.2.4)\n",
            "Requirement already satisfied: python-mecab-ko-dic in /usr/local/lib/python3.11/dist-packages (from python_mecab_ko->-r requirements.txt (line 36)) (2.1.1.post2)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.115.2->fastapi[standard]>=0.115.2->-r requirements.txt (line 37)) (0.46.2)\n",
            "Requirement already satisfied: einx>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from x_transformers->-r requirements.txt (line 38)) (0.3.0)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.11/dist-packages (from x_transformers->-r requirements.txt (line 38)) (0.7.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<=2.10.6->-r requirements.txt (line 40)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<=2.10.6->-r requirements.txt (line 40)) (2.27.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.13->-r requirements.txt (line 42)) (1.1.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.2->-r requirements.txt (line 37)) (0.0.7)\n",
            "Requirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.2->-r requirements.txt (line 37)) (2.2.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<5->-r requirements.txt (line 8)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<5->-r requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 19)) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 19)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 19)) (0.70.15)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.11/dist-packages (from einx>=0.3.0->x_transformers->-r requirements.txt (line 38)) (2.4.6)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.2->-r requirements.txt (line 37)) (2.7.0)\n",
            "Requirement already satisfied: rich-toolkit>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.2->-r requirements.txt (line 37)) (0.14.7)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (3.11.15)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<5->-r requirements.txt (line 8)) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<5->-r requirements.txt (line 8)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio<5->-r requirements.txt (line 8)) (0.16.0)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->funasr==1.0.27->-r requirements.txt (line 13)) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->funasr==1.0.27->-r requirements.txt (line 13)) (4.9.3)\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.11/dist-packages (from inflect>=0.3.1->g2p_en->-r requirements.txt (line 17)) (10.7.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from inflect>=0.3.1->g2p_en->-r requirements.txt (line 17)) (4.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio<5->-r requirements.txt (line 8)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio<5->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio<5->-r requirements.txt (line 8)) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio<5->-r requirements.txt (line 8)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio<5->-r requirements.txt (line 8)) (3.2.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.4->g2p_en->-r requirements.txt (line 17)) (8.2.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->modelscope==1.10.0->-r requirements.txt (line 19)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->modelscope==1.10.0->-r requirements.txt (line 19)) (2025.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa==0.10.2->-r requirements.txt (line 5)) (4.3.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25->modelscope==1.10.0->-r requirements.txt (line 19)) (3.4.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from robust-downloader>=0.0.2->fast_langdetect>=0.3.1->-r requirements.txt (line 29)) (6.9.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa==0.10.2->-r requirements.txt (line 5)) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa==0.10.2->-r requirements.txt (line 5)) (1.17.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio<5->-r requirements.txt (line 8)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio<5->-r requirements.txt (line 8)) (13.9.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.2->-r requirements.txt (line 37)) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.2->-r requirements.txt (line 37)) (1.1.0)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.2->-r requirements.txt (line 37)) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.2->-r requirements.txt (line 37)) (1.0.5)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime-gpu->-r requirements.txt (line 11)) (10.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper->funasr==1.0.27->-r requirements.txt (line 13)) (0.9.0)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.11/dist-packages (from oss2->funasr==1.0.27->-r requirements.txt (line 13)) (1.7)\n",
            "Requirement already satisfied: pycryptodome>=3.4.7 in /usr/local/lib/python3.11/dist-packages (from oss2->funasr==1.0.27->-r requirements.txt (line 13)) (3.23.0)\n",
            "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from oss2->funasr==1.0.27->-r requirements.txt (line 13)) (2.16.5)\n",
            "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /usr/local/lib/python3.11/dist-packages (from oss2->funasr==1.0.27->-r requirements.txt (line 13)) (2.16.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn->funasr==1.0.27->-r requirements.txt (line 13)) (0.5.13)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.4->-r requirements.txt (line 7)) (1.20.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2->funasr==1.0.27->-r requirements.txt (line 13)) (0.10.0)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2->funasr==1.0.27->-r requirements.txt (line 13)) (43.0.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa==0.10.2->-r requirements.txt (line 5)) (2.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<5->-r requirements.txt (line 8)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<5->-r requirements.txt (line 8)) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio<5->-r requirements.txt (line 8)) (0.1.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libao-common libao4 libid3tag0 libmad0 libopencore-amrnb0 libopencore-amrwb0\n",
            "  libsox-fmt-all libsox-fmt-alsa libsox-fmt-ao libsox-fmt-base libsox-fmt-mp3\n",
            "  libsox-fmt-oss libsox-fmt-pulse libsox3 libwavpack1\n",
            "Suggested packages:\n",
            "  libaudio2 libsndio6.1\n",
            "The following NEW packages will be installed:\n",
            "  libao-common libao4 libid3tag0 libmad0 libopencore-amrnb0 libopencore-amrwb0\n",
            "  libsox-dev libsox-fmt-all libsox-fmt-alsa libsox-fmt-ao libsox-fmt-base\n",
            "  libsox-fmt-mp3 libsox-fmt-oss libsox-fmt-pulse libsox3 libwavpack1\n",
            "0 upgraded, 16 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 1,053 kB of archives.\n",
            "After this operation, 4,061 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libao-common all 1.2.2+20180113-1.1ubuntu3 [6,568 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libao4 amd64 1.2.2+20180113-1.1ubuntu3 [35.2 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libid3tag0 amd64 0.15.1b-14 [31.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmad0 amd64 0.15.1b-10ubuntu1 [63.1 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrnb0 amd64 0.1.5-1 [94.8 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrwb0 amd64 0.1.5-1 [49.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox3 amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [240 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [11.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-ao amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [7,740 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwavpack1 amd64 5.4.0-1build2 [83.7 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-base amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [33.7 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-mp3 amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [17.3 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-oss amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [9,424 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-pulse amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [7,732 B]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-all amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [5,016 B]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-dev amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [356 kB]\n",
            "Fetched 1,053 kB in 1s (1,115 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 16.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libao-common.\n",
            "(Reading database ... 126111 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libao-common_1.2.2+20180113-1.1ubuntu3_all.deb ...\n",
            "Unpacking libao-common (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Selecting previously unselected package libao4:amd64.\n",
            "Preparing to unpack .../01-libao4_1.2.2+20180113-1.1ubuntu3_amd64.deb ...\n",
            "Unpacking libao4:amd64 (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Selecting previously unselected package libid3tag0:amd64.\n",
            "Preparing to unpack .../02-libid3tag0_0.15.1b-14_amd64.deb ...\n",
            "Unpacking libid3tag0:amd64 (0.15.1b-14) ...\n",
            "Selecting previously unselected package libmad0:amd64.\n",
            "Preparing to unpack .../03-libmad0_0.15.1b-10ubuntu1_amd64.deb ...\n",
            "Unpacking libmad0:amd64 (0.15.1b-10ubuntu1) ...\n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "Preparing to unpack .../04-libopencore-amrnb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../05-libopencore-amrwb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../06-libsox3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../07-libsox-fmt-alsa_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-ao:amd64.\n",
            "Preparing to unpack .../08-libsox-fmt-ao_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-ao:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libwavpack1:amd64.\n",
            "Preparing to unpack .../09-libwavpack1_5.4.0-1build2_amd64.deb ...\n",
            "Unpacking libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../10-libsox-fmt-base_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-mp3:amd64.\n",
            "Preparing to unpack .../11-libsox-fmt-mp3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-oss:amd64.\n",
            "Preparing to unpack .../12-libsox-fmt-oss_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-oss:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-pulse:amd64.\n",
            "Preparing to unpack .../13-libsox-fmt-pulse_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-pulse:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-all:amd64.\n",
            "Preparing to unpack .../14-libsox-fmt-all_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-all:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-dev:amd64.\n",
            "Preparing to unpack .../15-libsox-dev_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-dev:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-oss:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libao-common (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Setting up libid3tag0:amd64 (0.15.1b-14) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libao4:amd64 (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Setting up libmad0:amd64 (0.15.1b-10ubuntu1) ...\n",
            "Setting up libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-ao:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-pulse:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-all:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-dev:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python==0.2.0) (1.0.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (4.44.1)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.33.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Collecting gradio-client==1.10.3 (from gradio)\n",
            "  Downloading gradio_client-1.10.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.32.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.12)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.3->gradio) (12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.33.1-py3-none-any.whl (54.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.3-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.6/323.6 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gradio-client, gradio\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.3.0\n",
            "    Uninstalling gradio_client-1.3.0:\n",
            "      Successfully uninstalled gradio_client-1.3.0\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 4.44.1\n",
            "    Uninstalling gradio-4.44.1:\n",
            "      Successfully uninstalled gradio-4.44.1\n",
            "Successfully installed gradio-5.33.1 gradio-client-1.10.3\n"
          ]
        }
      ],
      "source": [
        "#!git clone https://github.com/dean9703111/GPT-SoVITS # 筆者 GitHub 因為較為早期，目前無法順利運行\n",
        "!git clone https://github.com/RVC-Boss/GPT-SoVITS # 因筆者的 GitHub 版本有狀況，附上看看官方的版本（但他們更新頻率高，需要運氣）\n",
        "%cd GPT-SoVITS/\n",
        "!rm -rf GPT_SoVITS/pretrained_models  # 刪除目標資料夾\n",
        "!git clone https://huggingface.co/lj1995/GPT-SoVITS GPT_SoVITS/pretrained_models  # 複製模型\n",
        "!pip install -r requirements.txt\n",
        "!sudo apt install ffmpeg\n",
        "!sudo apt install libsox-dev\n",
        "!pip install ffmpeg-python==0.2.0\n",
        "!pip install --upgrade gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZRVt9Kbcrma"
      },
      "source": [
        "## 3. 啟動程式\n",
        "點擊 Running on public URL: xxx，即可進入 Web UI 畫面"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "file_path = '/content/GPT-SoVITS/webui.py'\n",
        "with open(file_path, 'r') as file:\n",
        "    content = file.read()\n",
        "modified_content = content.replace(\"app.queue(concurrency_count=511, max_size=1022)\", \"app.queue(max_size=1022)\")\n",
        "with open(file_path, 'w') as file:\n",
        "    file.write(modified_content)\n",
        "file_path = '/content/GPT-SoVITS/GPT_SoVITS/inference_webui.py'\n",
        "with open(file_path, 'r') as file:\n",
        "    content = file.read()\n",
        "modified_content = content.replace(\"app.queue(concurrency_count=511, max_size=1022)\", \"app.queue(max_size=1022)\")\n",
        "with open(file_path, 'w') as file:\n",
        "    file.write(modified_content)"
      ],
      "metadata": {
        "id": "rTUzP9qwJF7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipwhois\n",
        "\n",
        "from ipwhois import IPWhois\n",
        "from requests import get\n",
        "\n",
        "ip = get('https://api.ipify.org').text\n",
        "whois = IPWhois(ip).lookup_rdap(depth=1)\n",
        "cidr = whois['network']['cidr']\n",
        "name = whois['network']['name']\n",
        "\n",
        "print('\\n')\n",
        "print('Provider:  ', name)\n",
        "print('Public IP: ', ip)\n",
        "print('CIDRs:     ', cidr)"
      ],
      "metadata": {
        "id": "0dpZ9FModdd4",
        "outputId": "51c139f6-9922-40b6-b48a-77fa8de08e73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipwhois\n",
            "  Downloading ipwhois-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: dnspython in /usr/local/lib/python3.11/dist-packages (from ipwhois) (2.7.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from ipwhois) (0.7.1)\n",
            "Downloading ipwhois-1.3.0-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.7/70.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ipwhois\n",
            "Successfully installed ipwhois-1.3.0\n",
            "\n",
            "\n",
            "Provider:   GOOGL-2\n",
            "Public IP:  34.16.223.127\n",
            "CIDRs:      34.4.5.0/24, 34.4.6.0/23, 34.4.8.0/21, 34.4.16.0/20, 34.4.32.0/19, 34.4.64.0/18, 34.4.128.0/17, 34.5.0.0/16, 34.6.0.0/15, 34.8.0.0/13, 34.16.0.0/12, 34.32.0.0/11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nest-asyncio pyngrok\n",
        "!ngrok config add-authtoken 2yIz1Ov16Z9De80KNxb74b5kk95_4n1D8XR8cM1CkXyyr2nyL"
      ],
      "metadata": {
        "id": "wJDADaOue6Xj",
        "outputId": "fee06e57-7c09-4bc0-b13d-8e4c97a8bfbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.11-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.11-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.11\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y ffmpeg libsndfile1\n"
      ],
      "metadata": {
        "id": "J5Hp5ruQnh9K",
        "outputId": "faadc30c-e67d-4777-f78b-51996d1f4ac6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connecting to security.\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connecting to security.\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,021 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,246 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,553 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,742 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,984 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,295 kB]\n",
            "Fetched 21.2 MB in 5s (4,036 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libsndfile1 is already the newest version (1.0.31-2ubuntu0.2).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/kevinwang676/GPT-SoVITS-v-3/resolve/main/badXT_71.wav"
      ],
      "metadata": {
        "id": "7Obj2eTIpV1O",
        "outputId": "b2572282-0b79-4612-f5c0-ff0b87b00176",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-11 06:40:02--  https://huggingface.co/kevinwang676/GPT-SoVITS-v-3/resolve/main/badXT_71.wav\n",
            "Resolving huggingface.co (huggingface.co)... 108.138.246.67, 108.138.246.79, 108.138.246.85, ...\n",
            "Connecting to huggingface.co (huggingface.co)|108.138.246.67|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/11/3a/113a0202dedf407db202e22b8d2d77af38374546001b642f270abb194d9b6da8/1c5e28420eb8c4506a1988d484fe9270b8422161d733c567abfccd74c106ceb9?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27badXT_71.wav%3B+filename%3D%22badXT_71.wav%22%3B&response-content-type=audio%2Fwave&Expires=1749627602&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0OTYyNzYwMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzExLzNhLzExM2EwMjAyZGVkZjQwN2RiMjAyZTIyYjhkMmQ3N2FmMzgzNzQ1NDYwMDFiNjQyZjI3MGFiYjE5NGQ5YjZkYTgvMWM1ZTI4NDIwZWI4YzQ1MDZhMTk4OGQ0ODRmZTkyNzBiODQyMjE2MWQ3MzNjNTY3YWJmY2NkNzRjMTA2Y2ViOT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=MvtNvfGjSwqkx5iuXai5rsvfTsivPLOGSF-EWVCM29TPcrD2CJEhIqXgeH9cfSu0kj7jyipVBZPlAyypIMLQvTdTm6nvWm9luT5AFuEFGpdOowr3rAau8gWyAs%7EKyRP5ZS1PIXUbj%7E44jqazbIpgdjB54Bd00UoH%7E7sM2jsLdVo8lANw%7EIhJGUehmamdFZ6ebTDnle03c5gpP8cVwQxH-nvbJZxxyjRxhD54f%7EGfpr0CIo1BWrRyNXQFdEQ5NBTy8DAo6wEhO2M5tXAnliYJ%7EkpU8c1RFOzMVPz5r7sj%7ESycSOBMlP6ZK4SqslR-RhKmvu0Uq9XsH957G1gMmdmCSw__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-06-11 06:40:02--  https://cdn-lfs-us-1.hf.co/repos/11/3a/113a0202dedf407db202e22b8d2d77af38374546001b642f270abb194d9b6da8/1c5e28420eb8c4506a1988d484fe9270b8422161d733c567abfccd74c106ceb9?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27badXT_71.wav%3B+filename%3D%22badXT_71.wav%22%3B&response-content-type=audio%2Fwave&Expires=1749627602&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0OTYyNzYwMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzExLzNhLzExM2EwMjAyZGVkZjQwN2RiMjAyZTIyYjhkMmQ3N2FmMzgzNzQ1NDYwMDFiNjQyZjI3MGFiYjE5NGQ5YjZkYTgvMWM1ZTI4NDIwZWI4YzQ1MDZhMTk4OGQ0ODRmZTkyNzBiODQyMjE2MWQ3MzNjNTY3YWJmY2NkNzRjMTA2Y2ViOT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=MvtNvfGjSwqkx5iuXai5rsvfTsivPLOGSF-EWVCM29TPcrD2CJEhIqXgeH9cfSu0kj7jyipVBZPlAyypIMLQvTdTm6nvWm9luT5AFuEFGpdOowr3rAau8gWyAs%7EKyRP5ZS1PIXUbj%7E44jqazbIpgdjB54Bd00UoH%7E7sM2jsLdVo8lANw%7EIhJGUehmamdFZ6ebTDnle03c5gpP8cVwQxH-nvbJZxxyjRxhD54f%7EGfpr0CIo1BWrRyNXQFdEQ5NBTy8DAo6wEhO2M5tXAnliYJ%7EkpU8c1RFOzMVPz5r7sj%7ESycSOBMlP6ZK4SqslR-RhKmvu0Uq9XsH957G1gMmdmCSw__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 3.167.212.49, 3.167.212.110, 3.167.212.43, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|3.167.212.49|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 794726 (776K) [audio/wave]\n",
            "Saving to: ‘badXT_71.wav’\n",
            "\n",
            "badXT_71.wav        100%[===================>] 776.10K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-06-11 06:40:02 (9.85 MB/s) - ‘badXT_71.wav’ saved [794726/794726]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!file badXT_71.wav"
      ],
      "metadata": {
        "id": "rKcNyJXupFpP",
        "outputId": "f1d2eb0f-ef2c-4f70-8f8d-eb51d2570867",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "badXT_71.wav: RIFF (little-endian) data, WAVE audio, Microsoft PCM, 16 bit, mono 44100 Hz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "\n",
        "audio_path = 'badXT_71.wav'  # your reference audio path\n",
        "y, sr = librosa.load(audio_path, sr=16000)\n",
        "print(f\"Loaded audio shape: {y.shape}, sample rate: {sr}\")\n"
      ],
      "metadata": {
        "id": "ZnH34MqJotaQ",
        "outputId": "8aea687f-34ad-4c17-c949-63f196310d4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded audio shape: (144160,), sample rate: 16000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/kevinwang676/GPT-SoVITS-v-3/blob/main/badXT_71.wav\n"
      ],
      "metadata": {
        "id": "SE5xynPGmfPU",
        "outputId": "bf07fc85-de2e-4686-f78f-b135ec31a8cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-10 06:54:28--  https://huggingface.co/kevinwang676/GPT-SoVITS-v-3/blob/main/badXT_71.wav\n",
            "Resolving huggingface.co (huggingface.co)... 3.169.137.19, 3.169.137.111, 3.169.137.119, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.169.137.19|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47684 (47K) [text/html]\n",
            "Saving to: ‘badXT_71.wav.1’\n",
            "\n",
            "badXT_71.wav.1      100%[===================>]  46.57K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2025-06-10 06:54:29 (10.3 MB/s) - ‘badXT_71.wav.1’ saved [47684/47684]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python api_v2.py -a 0.0.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WDDX5PXdFsc",
        "outputId": "846dcbed-e4f2-44ff-c75f-373547dcbdc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-11 06:40:57.324234: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749624057.347550    7279 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749624057.353678    7279 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-11 06:40:57.374095: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "---------------------------------------------TTS Config---------------------------------------------\n",
            "device              : cuda\n",
            "is_half             : True\n",
            "version             : v2\n",
            "t2s_weights_path    : GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s1bert25hz-5kh-longer-epoch=12-step=369668.ckpt\n",
            "vits_weights_path   : GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s2G2333k.pth\n",
            "bert_base_path      : GPT_SoVITS/pretrained_models/chinese-roberta-wwm-ext-large\n",
            "cnhuhbert_base_path : GPT_SoVITS/pretrained_models/chinese-hubert-base\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Loading Text2Semantic weights from GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s1bert25hz-5kh-longer-epoch=12-step=369668.ckpt\n",
            "Loading VITS weights from GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s2G2333k.pth. <All keys matched successfully>\n",
            "Loading BERT weights from GPT_SoVITS/pretrained_models/chinese-roberta-wwm-ext-large\n",
            "Loading CNHuBERT weights from GPT_SoVITS/pretrained_models/chinese-hubert-base\n",
            "INFO:pyngrok.ngrok:Opening tunnel named: http-9880-ed1f2bcf-c7a2-4366-9621-9ef1716d7009\n",
            "INFO:pyngrok.process.ngrok:t=2025-06-11T06:41:13+0000 lvl=info msg=\"no configuration paths supplied\"\n",
            "INFO:pyngrok.process.ngrok:t=2025-06-11T06:41:13+0000 lvl=info msg=\"using configuration at default config path\" path=/root/.config/ngrok/ngrok.yml\n",
            "INFO:pyngrok.process.ngrok:t=2025-06-11T06:41:13+0000 lvl=info msg=\"open config file\" path=/root/.config/ngrok/ngrok.yml err=nil\n",
            "INFO:pyngrok.process.ngrok:t=2025-06-11T06:41:13+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040 allow_hosts=[]\n",
            "INFO:pyngrok.process.ngrok:t=2025-06-11T06:41:13+0000 lvl=info msg=\"client session established\" obj=tunnels.session\n",
            "INFO:pyngrok.process.ngrok:t=2025-06-11T06:41:13+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "INFO:pyngrok.process.ngrok:t=2025-06-11T06:41:13+0000 lvl=info msg=start pg=/api/tunnels id=6a8d15226282d4ff\n",
            "INFO:pyngrok.process.ngrok:t=2025-06-11T06:41:13+0000 lvl=info msg=end pg=/api/tunnels id=6a8d15226282d4ff status=200 dur=274.862µs\n",
            "INFO:pyngrok.process.ngrok:t=2025-06-11T06:41:13+0000 lvl=info msg=start pg=/api/tunnels id=91e934bc104a5687\n",
            "INFO:pyngrok.process.ngrok:t=2025-06-11T06:41:13+0000 lvl=info msg=end pg=/api/tunnels id=91e934bc104a5687 status=200 dur=106.954µs\n",
            "INFO:pyngrok.process.ngrok:t=2025-06-11T06:41:13+0000 lvl=info msg=start pg=/api/tunnels id=63a75aa91d77c371\n",
            "INFO:pyngrok.process.ngrok:t=2025-06-11T06:41:13+0000 lvl=info msg=end pg=/api/tunnels id=63a75aa91d77c371 status=200 dur=88.063µs\n",
            "INFO:pyngrok.process.ngrok:t=2025-06-11T06:41:13+0000 lvl=info msg=start pg=/api/tunnels id=1dd86d317f1eec7c\n",
            "INFO:pyngrok.process.ngrok:t=2025-06-11T06:41:13+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=http-9880-ed1f2bcf-c7a2-4366-9621-9ef1716d7009 addr=http://localhost:9880 url=https://c2a1-34-16-223-127.ngrok-free.app\n",
            "INFO:pyngrok.process.ngrok:t=2025-06-11T06:41:13+0000 lvl=info msg=end pg=/api/tunnels id=1dd86d317f1eec7c status=201 dur=86.0343ms\n",
            "### DEBUG: Public URL: NgrokTunnel: \"https://c2a1-34-16-223-127.ngrok-free.app\" -> \"http://localhost:9880\"\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m7279\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:9880\u001b[0m (Press CTRL+C to quit)\n",
            "INFO:pyngrok.process.ngrok:t=2025-06-11T06:42:11+0000 lvl=info msg=\"join connections\" obj=join id=28d70891d6ff l=127.0.0.1:9880 r=[2001:b400:e453:7df1:4d35:40fc:8719:d037]:52252\n",
            "\u001b[32mINFO\u001b[0m:     2001:b400:e453:7df1:4d35:40fc:8719:d037:0 - \"\u001b[1mGET /tts?text=%E5%85%88%E5%B8%9D%E5%88%9B%E4%B8%9A%E6%9C%AA%E5%8D%8A%E8%80%8C%E4%B8%AD%E9%81%93%E5%B4%A9%E6%AE%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E4%B8%8B%E4%B8%89%E5%88%86%EF%BC%8C%E7%9B%8A%E5%B7%9E%E7%96%B2%E5%BC%8A%EF%BC%8C%E6%AD%A4%E8%AF%9A%E5%8D%B1%E6%80%A5%E5%AD%98%E4%BA%A1%E4%B9%8B%E7%A7%8B%E4%B9%9F%E3%80%82&text_lang=zh&ref_audio_path=badXT_71.wav&prompt_lang=zh&prompt_text=%E5%9D%8F%E5%A5%B3%E4%BA%BA%E5%94%B1%E8%AE%B0%E5%BD%95%E8%B6%85%E8%BF%87%E4%B8%89%E5%8D%81%E5%88%86%E9%92%9F%EF%BC%8C%E9%82%A3%E6%98%AF%E5%9B%A0%E4%B8%BA%E4%BB%A5%E5%89%8D%E7%9C%8B%E5%88%B0%E5%B0%8F%E6%96%B0%E5%B0%B1%E7%83%A6%E4%BA%86%EF%BC%8C%E6%A0%B9%E6%9C%AC%E4%B8%8D%E6%83%B3%E8%B7%9F%E5%B0%8F%E6%96%B0%E8%A7%81%E9%9D%A2%E3%80%82%E4%BD%86%E6%98%AF%E6%88%91%E4%B8%8D%E7%9F%A5%E9%81%93%E4%B8%BA%E4%BB%80%E4%B9%88%EF%BC%8C%E6%88%91%E5%AF%B9%E4%BD%A0%E4%BB%AC%E6%9C%89%E4%B8%80%E7%A7%8D%E7%89%B9%E5%88%AB%E7%9A%84%E6%84%9F%E8%A7%89%E3%80%82&text_split_method=cut5&batch_size=1&media_type=wav&streaming_mode=true HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "Set seed to 3816456800\n",
            "Parallel Inference Mode Enabled\n",
            "Segmented Return Mode Enabled\n",
            "Segmented Return Mode does not support Bucket Processing, Bucket Processing Disabled automatically\n",
            "Bucket Processing Mode Disabled\n",
            "\u001b[32mINFO\u001b[0m:     2001:b400:e453:7df1:4d35:40fc:8719:d037:0 - \"\u001b[1mGET /tts?text=%E5%85%88%E5%B8%9D%E5%88%9B%E4%B8%9A%E6%9C%AA%E5%8D%8A%E8%80%8C%E4%B8%AD%E9%81%93%E5%B4%A9%E6%AE%82%EF%BC%8C%E4%BB%8A%E5%A4%A9%E4%B8%8B%E4%B8%89%E5%88%86%EF%BC%8C%E7%9B%8A%E5%B7%9E%E7%96%B2%E5%BC%8A%EF%BC%8C%E6%AD%A4%E8%AF%9A%E5%8D%B1%E6%80%A5%E5%AD%98%E4%BA%A1%E4%B9%8B%E7%A7%8B%E4%B9%9F%E3%80%82&text_lang=zh&ref_audio_path=badXT_71.wav&prompt_lang=zh&prompt_text=%E5%9D%8F%E5%A5%B3%E4%BA%BA%E5%94%B1%E8%AE%B0%E5%BD%95%E8%B6%85%E8%BF%87%E4%B8%89%E5%8D%81%E5%88%86%E9%92%9F%EF%BC%8C%E9%82%A3%E6%98%AF%E5%9B%A0%E4%B8%BA%E4%BB%A5%E5%89%8D%E7%9C%8B%E5%88%B0%E5%B0%8F%E6%96%B0%E5%B0%B1%E7%83%A6%E4%BA%86%EF%BC%8C%E6%A0%B9%E6%9C%AC%E4%B8%8D%E6%83%B3%E8%B7%9F%E5%B0%8F%E6%96%B0%E8%A7%81%E9%9D%A2%E3%80%82%E4%BD%86%E6%98%AF%E6%88%91%E4%B8%8D%E7%9F%A5%E9%81%93%E4%B8%BA%E4%BB%80%E4%B9%88%EF%BC%8C%E6%88%91%E5%AF%B9%E4%BD%A0%E4%BB%AC%E6%9C%89%E4%B8%80%E7%A7%8D%E7%89%B9%E5%88%AB%E7%9A%84%E6%84%9F%E8%A7%89%E3%80%82&text_split_method=cut5&batch_size=1&media_type=wav&streaming_mode=true HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "INFO:pyngrok.process.ngrok:t=2025-06-11T06:42:11+0000 lvl=info msg=\"join connections\" obj=join id=8df7cf875180 l=127.0.0.1:9880 r=[2001:b400:e453:7df1:4d35:40fc:8719:d037]:52252\n",
            "Set seed to 872260028\n",
            "Parallel Inference Mode Enabled\n",
            "Segmented Return Mode Enabled\n",
            "Segmented Return Mode does not support Bucket Processing, Bucket Processing Disabled automatically\n",
            "Bucket Processing Mode Disabled\n",
            "Actual Input Reference Text: 坏女人唱记录超过三十分钟，那是因为以前看到小新就烦了，根本不想跟小新见面。但是我不知道为什么，我对你们有一种特别的感觉。\n",
            "INFO:fast_langdetect.infer:fast-langdetect: Downloading model from https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\n",
            "Actual Input Reference Text: 坏女人唱记录超过三十分钟，那是因为以前看到小新就烦了，根本不想跟小新见面。但是我不知道为什么，我对你们有一种特别的感觉。\n",
            "[\u001b[36m2025-06-11 06:42:14,293\u001b[0m][\u001b[32mINFO\u001b[0m] - Downloading https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin to lid.176.bin (125.2M)\u001b[0m\n",
            "INFO:robust_downloader.downloader:Downloading https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin to lid.176.bin (125.2M)\n",
            "100% 125M/125M [00:01<00:00, 72.8MB/s]\n",
            "Downloading g2pw model...\n",
            "Extracting g2pw model...\n",
            "############ Segment Text ############\n",
            "Actual Input Target Text:\n",
            "先帝创业未半而中道崩殂，今天下三分，益州疲弊，此诚危急存亡之秋也。\n",
            "Actual Input Target Text (after sentence segmentation):\n",
            "['先帝创业未半而中道崩殂，', '今天下三分，', '益州疲弊，', '此诚危急存亡之秋也。']\n",
            "############ 推理 ############\n",
            "############ Extract Text BERT Features ############\n",
            "  0% 0/1 [00:00<?, ?it/s]############ Segment Text ############\n",
            "Actual Input Target Text:\n",
            "先帝创业未半而中道崩殂，今天下三分，益州疲弊，此诚危急存亡之秋也。\n",
            "Actual Input Target Text (after sentence segmentation):\n",
            "['先帝创业未半而中道崩殂，', '今天下三分，', '益州疲弊，', '此诚危急存亡之秋也。']\n",
            "############ 推理 ############\n",
            "############ Extract Text BERT Features ############\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.63it/s]\n",
            "Processed text from the frontend (per sentence): ['先帝创业未半而中道崩殂,']\n",
            "############ Predict Semantic Token ############\n",
            "  0% 0/1500 [00:00<?, ?it/s]\n",
            "100% 1/1 [00:00<00:00,  7.59it/s]\n",
            "Processed text from the frontend (per sentence): ['先帝创业未半而中道崩殂,']\n",
            "############ Predict Semantic Token ############\n",
            "\n",
            "  0% 1/1500 [00:00<07:00,  3.56it/s]\n",
            "  0% 1/1500 [00:00<06:56,  3.60it/s]\u001b[A\n",
            "  1% 8/1500 [00:00<01:14, 20.03it/s]\n",
            "  1% 8/1500 [00:00<01:14, 20.13it/s]\u001b[A\n",
            "  1% 16/1500 [00:00<00:53, 27.78it/s]\n",
            "  1% 16/1500 [00:00<00:53, 27.71it/s]\u001b[A\n",
            "  1% 20/1500 [00:00<00:48, 30.53it/s]\n",
            "  2% 24/1500 [00:01<00:50, 29.00it/s]\n",
            "  2% 28/1500 [00:01<00:50, 29.09it/s]\n",
            "  2% 32/1500 [00:01<00:49, 29.91it/s]\n",
            "  2% 36/1500 [00:01<00:47, 30.84it/s]\n",
            "  3% 40/1500 [00:01<00:46, 31.24it/s]\n",
            "  3% 44/1500 [00:01<00:45, 32.25it/s]\n",
            "  3% 48/1500 [00:01<00:43, 33.38it/s]\n",
            "  3% 52/1500 [00:01<00:47, 30.19it/s]\n",
            "  4% 56/1500 [00:02<00:49, 29.44it/s]\n",
            "  4% 60/1500 [00:02<00:48, 29.89it/s]\n",
            "  4% 64/1500 [00:02<00:46, 30.80it/s]\n",
            "  5% 68/1500 [00:02<00:45, 31.41it/s]T2S Decoding EOS [240 -> 311]\n",
            "  5% 70/1500 [00:02<00:51, 27.81it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "  7% 98/1500 [00:03<00:36, 38.49it/s]T2S Decoding EOS [240 -> 342]\n",
            "  7% 101/1500 [00:03<00:47, 29.71it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "215.930\t0.005\t3.621\t0.743\n",
            "215.338\t0.003\t2.652\t1.627\n",
            "############ Extract Text BERT Features ############\n",
            "100% 1/1 [00:00<00:00, 20.09it/s]\n",
            "Processed text from the frontend (per sentence): ['今天下三分,']\n",
            "############ Predict Semantic Token ############\n",
            "  3% 41/1500 [00:00<00:17, 83.48it/s]T2S Decoding EOS [240 -> 282]\n",
            "  3% 41/1500 [00:00<00:18, 77.68it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "215.338\t0.003\t0.582\t0.511\n",
            "############ Extract Text BERT Features ############\n",
            "100% 1/1 [00:00<00:00, 41.33it/s]\n",
            "Processed text from the frontend (per sentence): ['益州疲弊,']\n",
            "############ Predict Semantic Token ############\n",
            "  1% 18/1500 [00:00<00:16, 87.52it/s]T2S Decoding EOS [240 -> 268]\n",
            "  2% 27/1500 [00:00<00:17, 85.06it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "215.338\t0.003\t0.344\t0.163\n",
            "############ Extract Text BERT Features ############\n",
            "100% 1/1 [00:00<00:00, 38.03it/s]\n",
            "Processed text from the frontend (per sentence): ['此诚危急存亡之秋也.']\n",
            "############ Predict Semantic Token ############\n",
            "  4% 63/1500 [00:00<00:16, 86.42it/s]T2S Decoding EOS [240 -> 304]\n",
            "  4% 63/1500 [00:00<00:17, 83.57it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "215.338\t0.003\t0.783\t0.156\n",
            "\u001b[32mINFO\u001b[0m:     2001:b400:e453:7df1:4d35:40fc:8719:d037:0 - \"\u001b[1mGET /tts?text=%E8%AB%8B%E8%A8%98%E5%BE%97%E6%8A%8A%E5%BA%A7%E4%BD%8D%E6%94%B6%E6%8B%BE%E6%95%B4%E9%BD%8A%EF%BC%8C%E6%A1%8C%E6%A4%85%E9%9D%A0%E6%94%8F%EF%BC%8C%E5%9E%83%E5%9C%BE%E5%B8%B6%E8%B5%B0%EF%BC%8C%E8%AC%9D%E8%AC%9D%E3%80%82&text_lang=zh&ref_audio_path=badXT_71.wav&prompt_lang=zh&prompt_text=%E5%9D%8F%E5%A5%B3%E4%BA%BA%E5%94%B1%E8%AE%B0%E5%BD%95%E8%B6%85%E8%BF%87%E4%B8%89%E5%8D%81%E5%88%86%E9%92%9F%EF%BC%8C%E9%82%A3%E6%98%AF%E5%9B%A0%E4%B8%BA%E4%BB%A5%E5%89%8D%E7%9C%8B%E5%88%B0%E5%B0%8F%E6%96%B0%E5%B0%B1%E7%83%A6%E4%BA%86%EF%BC%8C%E6%A0%B9%E6%9C%AC%E4%B8%8D%E6%83%B3%E8%B7%9F%E5%B0%8F%E6%96%B0%E8%A7%81%E9%9D%A2%E3%80%82%E4%BD%86%E6%98%AF%E6%88%91%E4%B8%8D%E7%9F%A5%E9%81%93%E4%B8%BA%E4%BB%80%E4%B9%88%EF%BC%8C%E6%88%91%E5%AF%B9%E4%BD%A0%E4%BB%AC%E6%9C%89%E4%B8%80%E7%A7%8D%E7%89%B9%E5%88%AB%E7%9A%84%E6%84%9F%E8%A7%89%E3%80%82&text_split_method=cut5&batch_size=1&media_type=wav&streaming_mode=true HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "INFO:pyngrok.process.ngrok:t=2025-06-11T06:47:14+0000 lvl=info msg=\"join connections\" obj=join id=fb7564c296c7 l=127.0.0.1:9880 r=[2001:b400:e453:7df1:4d35:40fc:8719:d037]:52252\n",
            "Set seed to 3091476705\n",
            "Parallel Inference Mode Enabled\n",
            "Segmented Return Mode Enabled\n",
            "Segmented Return Mode does not support Bucket Processing, Bucket Processing Disabled automatically\n",
            "Bucket Processing Mode Disabled\n",
            "Actual Input Reference Text: 坏女人唱记录超过三十分钟，那是因为以前看到小新就烦了，根本不想跟小新见面。但是我不知道为什么，我对你们有一种特别的感觉。\n",
            "############ Segment Text ############\n",
            "Actual Input Target Text:\n",
            "請記得把座位收拾整齊，桌椅靠攏，垃圾帶走，謝謝。\n",
            "Actual Input Target Text (after sentence segmentation):\n",
            "['請記得把座位收拾整齊，', '桌椅靠攏，', '垃圾帶走，謝謝。']\n",
            "############ 推理 ############\n",
            "############ Extract Text BERT Features ############\n",
            "100% 1/1 [00:00<00:00, 29.50it/s]\n",
            "Processed text from the frontend (per sentence): ['请记得把座位收拾整齐,']\n",
            "############ Predict Semantic Token ############\n",
            "  2% 26/1500 [00:00<00:18, 81.47it/s]\u001b[32mINFO\u001b[0m:     2001:b400:e453:7df1:4d35:40fc:8719:d037:0 - \"\u001b[1mGET /tts?text=%E8%AB%8B%E8%A8%98%E5%BE%97%E6%8A%8A%E5%BA%A7%E4%BD%8D%E6%94%B6%E6%8B%BE%E6%95%B4%E9%BD%8A%EF%BC%8C%E6%A1%8C%E6%A4%85%E9%9D%A0%E6%94%8F%EF%BC%8C%E5%9E%83%E5%9C%BE%E5%B8%B6%E8%B5%B0%EF%BC%8C%E8%AC%9D%E8%AC%9D%E3%80%82&text_lang=zh&ref_audio_path=badXT_71.wav&prompt_lang=zh&prompt_text=%E5%9D%8F%E5%A5%B3%E4%BA%BA%E5%94%B1%E8%AE%B0%E5%BD%95%E8%B6%85%E8%BF%87%E4%B8%89%E5%8D%81%E5%88%86%E9%92%9F%EF%BC%8C%E9%82%A3%E6%98%AF%E5%9B%A0%E4%B8%BA%E4%BB%A5%E5%89%8D%E7%9C%8B%E5%88%B0%E5%B0%8F%E6%96%B0%E5%B0%B1%E7%83%A6%E4%BA%86%EF%BC%8C%E6%A0%B9%E6%9C%AC%E4%B8%8D%E6%83%B3%E8%B7%9F%E5%B0%8F%E6%96%B0%E8%A7%81%E9%9D%A2%E3%80%82%E4%BD%86%E6%98%AF%E6%88%91%E4%B8%8D%E7%9F%A5%E9%81%93%E4%B8%BA%E4%BB%80%E4%B9%88%EF%BC%8C%E6%88%91%E5%AF%B9%E4%BD%A0%E4%BB%AC%E6%9C%89%E4%B8%80%E7%A7%8D%E7%89%B9%E5%88%AB%E7%9A%84%E6%84%9F%E8%A7%89%E3%80%82&text_split_method=cut5&batch_size=1&media_type=wav&streaming_mode=true HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "INFO:pyngrok.process.ngrok:t=2025-06-11T06:47:14+0000 lvl=info msg=\"join connections\" obj=join id=519505b8b6ae l=127.0.0.1:9880 r=[2001:b400:e453:7df1:4d35:40fc:8719:d037]:52252\n",
            "Set seed to 1134928439\n",
            "Parallel Inference Mode Enabled\n",
            "Segmented Return Mode Enabled\n",
            "Segmented Return Mode does not support Bucket Processing, Bucket Processing Disabled automatically\n",
            "Bucket Processing Mode Disabled\n",
            "Actual Input Reference Text: 坏女人唱记录超过三十分钟，那是因为以前看到小新就烦了，根本不想跟小新见面。但是我不知道为什么，我对你们有一种特别的感觉。\n",
            "############ Segment Text ############\n",
            "Actual Input Target Text:\n",
            "請記得把座位收拾整齊，桌椅靠攏，垃圾帶走，謝謝。\n",
            "Actual Input Target Text (after sentence segmentation):\n",
            "['請記得把座位收拾整齊，', '桌椅靠攏，', '垃圾帶走，謝謝。']\n",
            "############ 推理 ############\n",
            "############ Extract Text BERT Features ############\n",
            "\n",
            "100% 1/1 [00:00<00:00, 16.07it/s]\n",
            "Processed text from the frontend (per sentence): ['请记得把座位收拾整齐,']\n",
            "############ Predict Semantic Token ############\n",
            "\n",
            "  2% 35/1500 [00:00<00:21, 69.67it/s]\n",
            "  0% 4/1500 [00:00<00:40, 37.05it/s]\u001b[A\n",
            "  3% 43/1500 [00:00<00:29, 49.28it/s]T2S Decoding EOS [240 -> 284]\n",
            "  3% 43/1500 [00:00<00:26, 55.38it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "\n",
            "  1% 12/1500 [00:00<00:50, 29.52it/s]\u001b[A\n",
            "  1% 16/1500 [00:00<00:48, 30.75it/s]\u001b[A\n",
            "  1% 20/1500 [00:00<00:49, 29.82it/s]\u001b[A0.000\t0.000\t0.814\t0.450\n",
            "\n",
            "  2% 24/1500 [00:00<00:46, 31.98it/s]\u001b[A\n",
            "  2% 31/1500 [00:00<00:35, 41.53it/s]\u001b[A\n",
            "  3% 39/1500 [00:00<00:28, 50.45it/s]\u001b[A\n",
            "  3% 46/1500 [00:01<00:26, 54.76it/s]\u001b[AT2S Decoding EOS [240 -> 287]\n",
            "  3% 46/1500 [00:01<00:35, 41.20it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "0.000\t0.000\t1.187\t0.239\n",
            "############ Extract Text BERT Features ############\n",
            "100% 1/1 [00:00<00:00, 29.63it/s]\n",
            "Processed text from the frontend (per sentence): ['桌椅靠拢']\n",
            "############ Predict Semantic Token ############\n",
            "  1% 13/1500 [00:00<00:24, 61.08it/s]T2S Decoding EOS [240 -> 258]\n",
            "  1% 17/1500 [00:00<00:25, 57.74it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "0.000\t0.000\t0.334\t0.249\n",
            "############ Extract Text BERT Features ############\n",
            "100% 1/1 [00:00<00:00, 28.04it/s]\n",
            "Processed text from the frontend (per sentence): ['垃圾带走谢谢.']\n",
            "############ Predict Semantic Token ############\n",
            "  4% 54/1500 [00:00<00:21, 68.33it/s]T2S Decoding EOS [240 -> 300]\n",
            "  4% 59/1500 [00:00<00:21, 66.09it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "0.000\t0.000\t0.931\t0.243\n",
            "INFO:pyngrok.process.ngrok:t=2025-06-11T06:49:39+0000 lvl=info msg=\"join connections\" obj=join id=d588406a5f03 l=127.0.0.1:9880 r=[2001:b400:e453:7df1:4d35:40fc:8719:d037]:52252\n",
            "\u001b[32mINFO\u001b[0m:     2001:b400:e453:7df1:4d35:40fc:8719:d037:0 - \"\u001b[1mGET /tts?text=%E6%B3%95%E6%96%B0%E7%A4%BE%E5%92%8C%E8%B7%AF%E9%80%8F%E7%A4%BE%E5%A0%B1%E5%B0%8E%EF%BC%8C%E5%B7%B4%E6%96%AF%E5%91%8A%E8%A8%B4%E5%AA%92%E9%AB%94%EF%BC%9A%E3%80%8C%E6%88%91%E5%B7%B2%E5%AE%A3%E5%B8%83%E9%80%B2%E5%85%A5%E5%9C%B0%E6%96%B9%E7%B7%8A%E6%80%A5%E7%8B%80%E6%85%8B%EF%BC%8C%E4%B8%A6%E5%AE%A3%E5%B8%83%E6%B4%9B%E6%9D%89%E7%A3%AF%E5%B8%82%E4%B8%AD%E5%BF%83%E5%AF%A6%E6%96%BD%E5%AE%B5%E7%A6%81%EF%BC%8C%E4%BB%A5%E9%81%8F%E9%98%BB%E7%A0%B4%E5%A3%9E%E8%A1%8C%E7%82%BA%E5%92%8C%E5%8A%AB%E6%8E%A0%E6%83%85%E4%BA%8B%E3%80%82%E3%80%8D&text_lang=zh&ref_audio_path=badXT_71.wav&prompt_lang=zh&prompt_text=%E5%9D%8F%E5%A5%B3%E4%BA%BA%E5%94%B1%E8%AE%B0%E5%BD%95%E8%B6%85%E8%BF%87%E4%B8%89%E5%8D%81%E5%88%86%E9%92%9F%EF%BC%8C%E9%82%A3%E6%98%AF%E5%9B%A0%E4%B8%BA%E4%BB%A5%E5%89%8D%E7%9C%8B%E5%88%B0%E5%B0%8F%E6%96%B0%E5%B0%B1%E7%83%A6%E4%BA%86%EF%BC%8C%E6%A0%B9%E6%9C%AC%E4%B8%8D%E6%83%B3%E8%B7%9F%E5%B0%8F%E6%96%B0%E8%A7%81%E9%9D%A2%E3%80%82%E4%BD%86%E6%98%AF%E6%88%91%E4%B8%8D%E7%9F%A5%E9%81%93%E4%B8%BA%E4%BB%80%E4%B9%88%EF%BC%8C%E6%88%91%E5%AF%B9%E4%BD%A0%E4%BB%AC%E6%9C%89%E4%B8%80%E7%A7%8D%E7%89%B9%E5%88%AB%E7%9A%84%E6%84%9F%E8%A7%89%E3%80%82&text_split_method=cut5&batch_size=1&media_type=wav&streaming_mode=true HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "Set seed to 2317630834\n",
            "Parallel Inference Mode Enabled\n",
            "Segmented Return Mode Enabled\n",
            "Segmented Return Mode does not support Bucket Processing, Bucket Processing Disabled automatically\n",
            "Bucket Processing Mode Disabled\n",
            "Actual Input Reference Text: 坏女人唱记录超过三十分钟，那是因为以前看到小新就烦了，根本不想跟小新见面。但是我不知道为什么，我对你们有一种特别的感觉。\n",
            "############ Segment Text ############\n",
            "Actual Input Target Text:\n",
            "法新社和路透社報導，巴斯告訴媒體：「我已宣布進入地方緊急狀態，並宣布洛杉磯市中心實施宵禁，以遏阻破壞行為和劫掠情事。」\n",
            "Actual Input Target Text (after sentence segmentation):\n",
            "['法新社和路透社報導，', '巴斯告訴媒體：', '「我已宣布進入地方緊急狀態，', '並宣布洛杉磯市中心實施宵禁，', '以遏阻破壞行為和劫掠情事。」。']\n",
            "############ 推理 ############\n",
            "############ Extract Text BERT Features ############\n",
            "100% 1/1 [00:00<00:00, 29.94it/s]\n",
            "Processed text from the frontend (per sentence): ['法新社和路透社报导,']\n",
            "############ Predict Semantic Token ############\n",
            "  2% 28/1500 [00:00<00:16, 88.42it/s]INFO:pyngrok.process.ngrok:t=2025-06-11T06:49:39+0000 lvl=info msg=\"join connections\" obj=join id=132163cd5c89 l=127.0.0.1:9880 r=[2001:b400:e453:7df1:4d35:40fc:8719:d037]:52252\n",
            "\u001b[32mINFO\u001b[0m:     2001:b400:e453:7df1:4d35:40fc:8719:d037:0 - \"\u001b[1mGET /tts?text=%E6%B3%95%E6%96%B0%E7%A4%BE%E5%92%8C%E8%B7%AF%E9%80%8F%E7%A4%BE%E5%A0%B1%E5%B0%8E%EF%BC%8C%E5%B7%B4%E6%96%AF%E5%91%8A%E8%A8%B4%E5%AA%92%E9%AB%94%EF%BC%9A%E3%80%8C%E6%88%91%E5%B7%B2%E5%AE%A3%E5%B8%83%E9%80%B2%E5%85%A5%E5%9C%B0%E6%96%B9%E7%B7%8A%E6%80%A5%E7%8B%80%E6%85%8B%EF%BC%8C%E4%B8%A6%E5%AE%A3%E5%B8%83%E6%B4%9B%E6%9D%89%E7%A3%AF%E5%B8%82%E4%B8%AD%E5%BF%83%E5%AF%A6%E6%96%BD%E5%AE%B5%E7%A6%81%EF%BC%8C%E4%BB%A5%E9%81%8F%E9%98%BB%E7%A0%B4%E5%A3%9E%E8%A1%8C%E7%82%BA%E5%92%8C%E5%8A%AB%E6%8E%A0%E6%83%85%E4%BA%8B%E3%80%82%E3%80%8D&text_lang=zh&ref_audio_path=badXT_71.wav&prompt_lang=zh&prompt_text=%E5%9D%8F%E5%A5%B3%E4%BA%BA%E5%94%B1%E8%AE%B0%E5%BD%95%E8%B6%85%E8%BF%87%E4%B8%89%E5%8D%81%E5%88%86%E9%92%9F%EF%BC%8C%E9%82%A3%E6%98%AF%E5%9B%A0%E4%B8%BA%E4%BB%A5%E5%89%8D%E7%9C%8B%E5%88%B0%E5%B0%8F%E6%96%B0%E5%B0%B1%E7%83%A6%E4%BA%86%EF%BC%8C%E6%A0%B9%E6%9C%AC%E4%B8%8D%E6%83%B3%E8%B7%9F%E5%B0%8F%E6%96%B0%E8%A7%81%E9%9D%A2%E3%80%82%E4%BD%86%E6%98%AF%E6%88%91%E4%B8%8D%E7%9F%A5%E9%81%93%E4%B8%BA%E4%BB%80%E4%B9%88%EF%BC%8C%E6%88%91%E5%AF%B9%E4%BD%A0%E4%BB%AC%E6%9C%89%E4%B8%80%E7%A7%8D%E7%89%B9%E5%88%AB%E7%9A%84%E6%84%9F%E8%A7%89%E3%80%82&text_split_method=cut5&batch_size=1&media_type=wav&streaming_mode=true HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "Set seed to 1269869867\n",
            "Parallel Inference Mode Enabled\n",
            "Segmented Return Mode Enabled\n",
            "Segmented Return Mode does not support Bucket Processing, Bucket Processing Disabled automatically\n",
            "Bucket Processing Mode Disabled\n",
            "Actual Input Reference Text: 坏女人唱记录超过三十分钟，那是因为以前看到小新就烦了，根本不想跟小新见面。但是我不知道为什么，我对你们有一种特别的感觉。\n",
            "############ Segment Text ############\n",
            "Actual Input Target Text:\n",
            "法新社和路透社報導，巴斯告訴媒體：「我已宣布進入地方緊急狀態，並宣布洛杉磯市中心實施宵禁，以遏阻破壞行為和劫掠情事。」\n",
            "Actual Input Target Text (after sentence segmentation):\n",
            "['法新社和路透社報導，', '巴斯告訴媒體：', '「我已宣布進入地方緊急狀態，', '並宣布洛杉磯市中心實施宵禁，', '以遏阻破壞行為和劫掠情事。」。']\n",
            "############ 推理 ############\n",
            "############ Extract Text BERT Features ############\n",
            "\n",
            "100% 1/1 [00:00<00:00, 19.24it/s]\n",
            "Processed text from the frontend (per sentence): ['法新社和路透社报导,']\n",
            "############ Predict Semantic Token ############\n",
            "\n",
            "  2% 37/1500 [00:00<00:21, 66.95it/s]\n",
            "  0% 4/1500 [00:00<00:45, 32.78it/s]\u001b[A\n",
            "  3% 45/1500 [00:00<00:28, 51.40it/s]\n",
            "  1% 12/1500 [00:00<00:43, 34.19it/s]\u001b[AT2S Decoding EOS [240 -> 288]\n",
            "  3% 47/1500 [00:00<00:25, 57.62it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "\n",
            "  1% 17/1500 [00:00<00:40, 36.59it/s]\u001b[A\n",
            "  1% 22/1500 [00:00<00:37, 39.79it/s]\u001b[A0.000\t0.000\t0.852\t0.263\n",
            "\n",
            "  2% 29/1500 [00:00<00:30, 48.05it/s]\u001b[A\n",
            "  3% 38/1500 [00:00<00:24, 60.17it/s]\u001b[A\n",
            "  3% 47/1500 [00:00<00:21, 67.76it/s]\u001b[AT2S Decoding EOS [240 -> 290]\n",
            "  3% 49/1500 [00:00<00:27, 52.12it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "0.000\t0.000\t0.996\t0.163\n",
            "############ Extract Text BERT Features ############\n",
            "100% 1/1 [00:00<00:00, 39.98it/s]\n",
            "Processed text from the frontend (per sentence): ['巴斯告诉媒体,']\n",
            "############ Predict Semantic Token ############\n",
            "  2% 25/1500 [00:00<00:18, 78.85it/s]T2S Decoding EOS [240 -> 273]\n",
            "  2% 32/1500 [00:00<00:19, 76.46it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "0.000\t0.000\t0.446\t0.178\n",
            "############ Extract Text BERT Features ############\n",
            "100% 1/1 [00:00<00:00, 35.32it/s]\n",
            "Processed text from the frontend (per sentence): ['我已宣布进入地方紧急状态,']\n",
            "############ Predict Semantic Token ############\n",
            "  4% 53/1500 [00:00<00:17, 83.11it/s]T2S Decoding EOS [240 -> 298]\n",
            "  4% 57/1500 [00:00<00:17, 82.17it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "0.000\t0.000\t0.725\t0.164\n",
            "############ Extract Text BERT Features ############\n",
            "100% 1/1 [00:00<00:00, 22.89it/s]\n",
            "Processed text from the frontend (per sentence): ['并宣布洛杉矶市中心实施宵禁,']\n",
            "############ Predict Semantic Token ############\n",
            "  4% 63/1500 [00:01<00:23, 60.30it/s]T2S Decoding EOS [240 -> 305]\n",
            "  4% 64/1500 [00:01<00:23, 60.13it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "0.000\t0.000\t1.112\t0.232\n",
            "############ Extract Text BERT Features ############\n",
            "100% 1/1 [00:00<00:00, 26.42it/s]\n",
            "Processed text from the frontend (per sentence): ['以遏阻破坏行为和劫掠情事.']\n",
            "############ Predict Semantic Token ############\n",
            "  6% 86/1500 [00:01<00:22, 63.47it/s]T2S Decoding EOS [240 -> 329]\n",
            "  6% 88/1500 [00:01<00:22, 63.80it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "0.000\t0.000\t1.420\t0.253\n",
            "INFO:pyngrok.process.ngrok:t=2025-06-11T06:52:29+0000 lvl=info msg=\"join connections\" obj=join id=6c3017f41bf3 l=127.0.0.1:9880 r=[2001:b400:e453:7df1:4d35:40fc:8719:d037]:52252\n",
            "\u001b[32mINFO\u001b[0m:     2001:b400:e453:7df1:4d35:40fc:8719:d037:0 - \"\u001b[1mGET /tts?text=%E8%80%8C%E4%B8%94%E4%BB%A4%E5%8F%B0%E7%81%A3%E7%94%A8%E6%88%B6%E6%8C%AF%E5%A5%AE%E7%9A%84%E6%98%AF%EF%BC%8CApple%20Intelligence%E7%B5%82%E6%96%BC%E7%A2%BA%E5%AE%9A%E5%B0%87%E6%8E%A8%E5%87%BA%E7%B9%81%E9%AB%94%E4%B8%AD%E6%96%87%E7%89%88%EF%BC%8C%E9%A0%90%E8%A8%88%E4%BB%8A%E5%B9%B4%E4%B8%8A%E5%B8%82%E3%80%82&text_lang=zh&ref_audio_path=badXT_71.wav&prompt_lang=zh&prompt_text=%E5%9D%8F%E5%A5%B3%E4%BA%BA%E5%94%B1%E8%AE%B0%E5%BD%95%E8%B6%85%E8%BF%87%E4%B8%89%E5%8D%81%E5%88%86%E9%92%9F%EF%BC%8C%E9%82%A3%E6%98%AF%E5%9B%A0%E4%B8%BA%E4%BB%A5%E5%89%8D%E7%9C%8B%E5%88%B0%E5%B0%8F%E6%96%B0%E5%B0%B1%E7%83%A6%E4%BA%86%EF%BC%8C%E6%A0%B9%E6%9C%AC%E4%B8%8D%E6%83%B3%E8%B7%9F%E5%B0%8F%E6%96%B0%E8%A7%81%E9%9D%A2%E3%80%82%E4%BD%86%E6%98%AF%E6%88%91%E4%B8%8D%E7%9F%A5%E9%81%93%E4%B8%BA%E4%BB%80%E4%B9%88%EF%BC%8C%E6%88%91%E5%AF%B9%E4%BD%A0%E4%BB%AC%E6%9C%89%E4%B8%80%E7%A7%8D%E7%89%B9%E5%88%AB%E7%9A%84%E6%84%9F%E8%A7%89%E3%80%82&text_split_method=cut5&batch_size=1&media_type=wav&streaming_mode=true HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "Set seed to 121667090\n",
            "Parallel Inference Mode Enabled\n",
            "Segmented Return Mode Enabled\n",
            "Segmented Return Mode does not support Bucket Processing, Bucket Processing Disabled automatically\n",
            "Bucket Processing Mode Disabled\n",
            "Actual Input Reference Text: 坏女人唱记录超过三十分钟，那是因为以前看到小新就烦了，根本不想跟小新见面。但是我不知道为什么，我对你们有一种特别的感觉。\n",
            "############ Segment Text ############\n",
            "Actual Input Target Text:\n",
            "而且令台灣用戶振奮的是，Apple Intelligence終於確定將推出繁體中文版，預計今年上市。\n",
            "Actual Input Target Text (after sentence segmentation):\n",
            "['而且令台灣用戶振奮的是，', 'Apple Intelligence終於確定將推出繁體中文版，', '預計今年上市。']\n",
            "############ 推理 ############\n",
            "############ Extract Text BERT Features ############\n",
            "100% 1/1 [00:00<00:00, 29.04it/s]\n",
            "Processed text from the frontend (per sentence): ['而且令台湾用户振奋的是,']\n",
            "############ Predict Semantic Token ############\n",
            "  4% 55/1500 [00:00<00:16, 86.51it/s]INFO:pyngrok.process.ngrok:t=2025-06-11T06:52:30+0000 lvl=info msg=\"join connections\" obj=join id=0338c753412d l=127.0.0.1:9880 r=[2001:b400:e453:7df1:4d35:40fc:8719:d037]:52252\n",
            "\u001b[32mINFO\u001b[0m:     2001:b400:e453:7df1:4d35:40fc:8719:d037:0 - \"\u001b[1mGET /tts?text=%E8%80%8C%E4%B8%94%E4%BB%A4%E5%8F%B0%E7%81%A3%E7%94%A8%E6%88%B6%E6%8C%AF%E5%A5%AE%E7%9A%84%E6%98%AF%EF%BC%8CApple%20Intelligence%E7%B5%82%E6%96%BC%E7%A2%BA%E5%AE%9A%E5%B0%87%E6%8E%A8%E5%87%BA%E7%B9%81%E9%AB%94%E4%B8%AD%E6%96%87%E7%89%88%EF%BC%8C%E9%A0%90%E8%A8%88%E4%BB%8A%E5%B9%B4%E4%B8%8A%E5%B8%82%E3%80%82&text_lang=zh&ref_audio_path=badXT_71.wav&prompt_lang=zh&prompt_text=%E5%9D%8F%E5%A5%B3%E4%BA%BA%E5%94%B1%E8%AE%B0%E5%BD%95%E8%B6%85%E8%BF%87%E4%B8%89%E5%8D%81%E5%88%86%E9%92%9F%EF%BC%8C%E9%82%A3%E6%98%AF%E5%9B%A0%E4%B8%BA%E4%BB%A5%E5%89%8D%E7%9C%8B%E5%88%B0%E5%B0%8F%E6%96%B0%E5%B0%B1%E7%83%A6%E4%BA%86%EF%BC%8C%E6%A0%B9%E6%9C%AC%E4%B8%8D%E6%83%B3%E8%B7%9F%E5%B0%8F%E6%96%B0%E8%A7%81%E9%9D%A2%E3%80%82%E4%BD%86%E6%98%AF%E6%88%91%E4%B8%8D%E7%9F%A5%E9%81%93%E4%B8%BA%E4%BB%80%E4%B9%88%EF%BC%8C%E6%88%91%E5%AF%B9%E4%BD%A0%E4%BB%AC%E6%9C%89%E4%B8%80%E7%A7%8D%E7%89%B9%E5%88%AB%E7%9A%84%E6%84%9F%E8%A7%89%E3%80%82&text_split_method=cut5&batch_size=1&media_type=wav&streaming_mode=true HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "Set seed to 3139641328\n",
            "Parallel Inference Mode Enabled\n",
            "Segmented Return Mode Enabled\n",
            "Segmented Return Mode does not support Bucket Processing, Bucket Processing Disabled automatically\n",
            "Bucket Processing Mode Disabled\n",
            "Actual Input Reference Text: 坏女人唱记录超过三十分钟，那是因为以前看到小新就烦了，根本不想跟小新见面。但是我不知道为什么，我对你们有一种特别的感觉。\n",
            "############ Segment Text ############\n",
            "Actual Input Target Text:\n",
            "而且令台灣用戶振奮的是，Apple Intelligence終於確定將推出繁體中文版，預計今年上市。\n",
            "Actual Input Target Text (after sentence segmentation):\n",
            "['而且令台灣用戶振奮的是，', 'Apple Intelligence終於確定將推出繁體中文版，', '預計今年上市。']\n",
            "############ 推理 ############\n",
            "############ Extract Text BERT Features ############\n",
            "\n",
            "100% 1/1 [00:00<00:00, 20.13it/s]\n",
            "Processed text from the frontend (per sentence): ['而且令台湾用户振奋的是,']\n",
            "############ Predict Semantic Token ############\n",
            "\n",
            "  0% 0/1500 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 64/1500 [00:00<00:24, 58.61it/s]\n",
            "  1% 9/1500 [00:00<00:38, 38.44it/s]\u001b[A\n",
            "  5% 71/1500 [00:01<00:27, 51.32it/s]\n",
            "  5% 77/1500 [00:01<00:29, 47.47it/s]\n",
            "  1% 21/1500 [00:00<00:38, 38.31it/s]\u001b[A\n",
            "  6% 83/1500 [00:01<00:32, 44.21it/s]T2S Decoding EOS [240 -> 325]\n",
            "  6% 84/1500 [00:01<00:24, 57.73it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "\n",
            "  2% 29/1500 [00:00<00:39, 37.45it/s]\u001b[A\n",
            "  2% 34/1500 [00:00<00:37, 39.24it/s]\u001b[A\n",
            "  3% 39/1500 [00:00<00:35, 41.61it/s]\u001b[A0.000\t0.000\t1.492\t0.254\n",
            "\n",
            "  3% 47/1500 [00:01<00:28, 51.13it/s]\u001b[A\n",
            "  4% 57/1500 [00:01<00:22, 63.26it/s]\u001b[AT2S Decoding EOS [240 -> 298]\n",
            "  4% 57/1500 [00:01<00:31, 46.48it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "0.000\t0.000\t1.280\t0.162\n",
            "############ Extract Text BERT Features ############\n",
            "  0% 0/1 [00:00<?, ?it/s][nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/cmudict.zip.\n",
            "  0% 0/1 [00:06<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/TTS_infer_pack/TTS.py\", line 1176, in run\n",
            "    item = make_batch(item)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/TTS_infer_pack/TTS.py\", line 1141, in make_batch\n",
            "    phones, bert_features, norm_text = self.text_preprocessor.segment_and_extract_feature_for_text(\n",
            "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/TTS_infer_pack/TextPreprocessor.py\", line 120, in segment_and_extract_feature_for_text\n",
            "    return self.get_phones_and_bert(text, language, version)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/TTS_infer_pack/TextPreprocessor.py\", line 179, in get_phones_and_bert\n",
            "    phones, word2ph, norm_text = self.clean_text_inf(textlist[i], lang, version)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/TTS_infer_pack/TextPreprocessor.py\", line 210, in clean_text_inf\n",
            "    phones, word2ph, norm_text = clean_text(text, language, version)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/text/cleaner.py\", line 47, in clean_text\n",
            "    phones = language_module.g2p(norm_text)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/text/english.py\", line 365, in g2p\n",
            "    phone_list = _g2p(text)\n",
            "                 ^^^^^^^^^^\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/text/english.py\", line 273, in __call__\n",
            "    tokens = pos_tag(words)  # tuples of (word, tag)\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nltk/tag/__init__.py\", line 168, in pos_tag\n",
            "    tagger = _get_tagger(lang)\n",
            "             ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nltk/tag/__init__.py\", line 110, in _get_tagger\n",
            "    tagger = PerceptronTagger()\n",
            "             ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nltk/tag/perceptron.py\", line 183, in __init__\n",
            "    self.load_from_json(lang)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nltk/tag/perceptron.py\", line 273, in load_from_json\n",
            "    loc = find(f\"taggers/averaged_perceptron_tagger_{lang}/\")\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nltk/data.py\", line 579, in find\n",
            "    raise LookupError(resource_not_found)\n",
            "LookupError: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Loading Text2Semantic weights from GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s1bert25hz-5kh-longer-epoch=12-step=369668.ckpt\n",
            "Loading VITS weights from GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s2G2333k.pth. <All keys matched successfully>\n",
            "\u001b[31mERROR\u001b[0m:    Exception in ASGI application\n",
            "  + Exception Group Traceback (most recent call last):\n",
            "  |   File \"/usr/local/lib/python3.11/dist-packages/starlette/_utils.py\", line 76, in collapse_excgroups\n",
            "  |     yield\n",
            "  |   File \"/usr/local/lib/python3.11/dist-packages/starlette/responses.py\", line 263, in __call__\n",
            "  |     async with anyio.create_task_group() as task_group:\n",
            "  |   File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n",
            "  |     raise BaseExceptionGroup(\n",
            "  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n",
            "  +-+---------------- 1 ----------------\n",
            "    | Traceback (most recent call last):\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n",
            "    |     result = await app(  # type: ignore[func-returns-value]\n",
            "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    |     return await self.app(scope, receive, send)\n",
            "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/fastapi/applications.py\", line 1054, in __call__\n",
            "    |     await super().__call__(scope, receive, send)\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/starlette/applications.py\", line 112, in __call__\n",
            "    |     await self.middleware_stack(scope, receive, send)\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py\", line 187, in __call__\n",
            "    |     raise exc\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py\", line 165, in __call__\n",
            "    |     await self.app(scope, receive, _send)\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n",
            "    |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    |     raise exc\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    |     await app(scope, receive, sender)\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 714, in __call__\n",
            "    |     await self.middleware_stack(scope, receive, send)\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 734, in app\n",
            "    |     await route.handle(scope, receive, send)\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 288, in handle\n",
            "    |     await self.app(scope, receive, send)\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 76, in app\n",
            "    |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    |     raise exc\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    |     await app(scope, receive, sender)\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 74, in app\n",
            "    |     await response(scope, receive, send)\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/starlette/responses.py\", line 262, in __call__\n",
            "    |     with collapse_excgroups():\n",
            "    |   File \"/usr/lib/python3.11/contextlib.py\", line 158, in __exit__\n",
            "    |     self.gen.throw(typ, value, traceback)\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n",
            "    |     raise exc\n",
            "    |   File \"/usr/lib/python3.11/asyncio/tasks.py\", line 279, in __step\n",
            "    |     result = coro.throw(exc)\n",
            "    |              ^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/starlette/responses.py\", line 266, in wrap\n",
            "    |     await func()\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/starlette/responses.py\", line 246, in stream_response\n",
            "    |     async for chunk in self.body_iterator:\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/starlette/concurrency.py\", line 60, in iterate_in_threadpool\n",
            "    |     yield await anyio.to_thread.run_sync(_next, as_iterator)\n",
            "    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    |     return await get_async_backend().run_sync_in_worker_thread(\n",
            "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    |     return await future\n",
            "    |            ^^^^^^^^^^^^\n",
            "    |   File \"/usr/lib/python3.11/asyncio/futures.py\", line 287, in __await__\n",
            "    |     yield self  # This tells Task to wait for completion.\n",
            "    |     ^^^^^^^^^^\n",
            "    |   File \"/usr/lib/python3.11/asyncio/tasks.py\", line 349, in __wakeup\n",
            "    |     future.result()\n",
            "    |   File \"/usr/lib/python3.11/asyncio/futures.py\", line 203, in result\n",
            "    |     raise self._exception.with_traceback(self._exception_tb)\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    |     result = context.run(func, *args)\n",
            "    |              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/starlette/concurrency.py\", line 49, in _next\n",
            "    |     return next(iterator)\n",
            "    |            ^^^^^^^^^^^^^^\n",
            "    |   File \"/content/GPT-SoVITS/api_v2.py\", line 355, in streaming_generator\n",
            "    |     for sr, chunk in tts_generator:\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 57, in generator_context\n",
            "    |     response = gen.send(request)\n",
            "    |                ^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/content/GPT-SoVITS/GPT_SoVITS/TTS_infer_pack/TTS.py\", line 1337, in run\n",
            "    |     raise e\n",
            "    |   File \"/content/GPT-SoVITS/GPT_SoVITS/TTS_infer_pack/TTS.py\", line 1176, in run\n",
            "    |     item = make_batch(item)\n",
            "    |            ^^^^^^^^^^^^^^^^\n",
            "    |   File \"/content/GPT-SoVITS/GPT_SoVITS/TTS_infer_pack/TTS.py\", line 1141, in make_batch\n",
            "    |     phones, bert_features, norm_text = self.text_preprocessor.segment_and_extract_feature_for_text(\n",
            "    |                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/content/GPT-SoVITS/GPT_SoVITS/TTS_infer_pack/TextPreprocessor.py\", line 120, in segment_and_extract_feature_for_text\n",
            "    |     return self.get_phones_and_bert(text, language, version)\n",
            "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/content/GPT-SoVITS/GPT_SoVITS/TTS_infer_pack/TextPreprocessor.py\", line 179, in get_phones_and_bert\n",
            "    |     phones, word2ph, norm_text = self.clean_text_inf(textlist[i], lang, version)\n",
            "    |                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/content/GPT-SoVITS/GPT_SoVITS/TTS_infer_pack/TextPreprocessor.py\", line 210, in clean_text_inf\n",
            "    |     phones, word2ph, norm_text = clean_text(text, language, version)\n",
            "    |                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/content/GPT-SoVITS/GPT_SoVITS/text/cleaner.py\", line 47, in clean_text\n",
            "    |     phones = language_module.g2p(norm_text)\n",
            "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/content/GPT-SoVITS/GPT_SoVITS/text/english.py\", line 365, in g2p\n",
            "    |     phone_list = _g2p(text)\n",
            "    |                  ^^^^^^^^^^\n",
            "    |   File \"/content/GPT-SoVITS/GPT_SoVITS/text/english.py\", line 273, in __call__\n",
            "    |     tokens = pos_tag(words)  # tuples of (word, tag)\n",
            "    |              ^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/nltk/tag/__init__.py\", line 168, in pos_tag\n",
            "    |     tagger = _get_tagger(lang)\n",
            "    |              ^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/nltk/tag/__init__.py\", line 110, in _get_tagger\n",
            "    |     tagger = PerceptronTagger()\n",
            "    |              ^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/nltk/tag/perceptron.py\", line 183, in __init__\n",
            "    |     self.load_from_json(lang)\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/nltk/tag/perceptron.py\", line 273, in load_from_json\n",
            "    |     loc = find(f\"taggers/averaged_perceptron_tagger_{lang}/\")\n",
            "    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/local/lib/python3.11/dist-packages/nltk/data.py\", line 579, in find\n",
            "    |     raise LookupError(resource_not_found)\n",
            "    | LookupError: \n",
            "    | **********************************************************************\n",
            "    |   Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "    |   Please use the NLTK Downloader to obtain the resource:\n",
            "    | \n",
            "    |   \u001b[31m>>> import nltk\n",
            "    |   >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "    |   \u001b[0m\n",
            "    |   For more information see: https://www.nltk.org/data.html\n",
            "    | \n",
            "    |   Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "    | \n",
            "    |   Searched in:\n",
            "    |     - '/root/nltk_data'\n",
            "    |     - '/usr/nltk_data'\n",
            "    |     - '/usr/share/nltk_data'\n",
            "    |     - '/usr/lib/nltk_data'\n",
            "    |     - '/usr/share/nltk_data'\n",
            "    |     - '/usr/local/share/nltk_data'\n",
            "    |     - '/usr/lib/nltk_data'\n",
            "    |     - '/usr/local/lib/nltk_data'\n",
            "    | **********************************************************************\n",
            "    | \n",
            "    +------------------------------------\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fastapi/applications.py\", line 1054, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/applications.py\", line 112, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py\", line 187, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py\", line 165, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 714, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 734, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 288, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 76, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 74, in app\n",
            "    await response(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/responses.py\", line 262, in __call__\n",
            "    with collapse_excgroups():\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 158, in __exit__\n",
            "    self.gen.throw(typ, value, traceback)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_utils.py\", line 82, in collapse_excgroups\n",
            "    raise exc\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 279, in __step\n",
            "    result = coro.throw(exc)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/responses.py\", line 266, in wrap\n",
            "    await func()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/responses.py\", line 246, in stream_response\n",
            "    async for chunk in self.body_iterator:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/concurrency.py\", line 60, in iterate_in_threadpool\n",
            "    yield await anyio.to_thread.run_sync(_next, as_iterator)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/futures.py\", line 287, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "    ^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 349, in __wakeup\n",
            "    future.result()\n",
            "  File \"/usr/lib/python3.11/asyncio/futures.py\", line 203, in result\n",
            "    raise self._exception.with_traceback(self._exception_tb)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/concurrency.py\", line 49, in _next\n",
            "    return next(iterator)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/content/GPT-SoVITS/api_v2.py\", line 355, in streaming_generator\n",
            "    for sr, chunk in tts_generator:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 57, in generator_context\n",
            "    response = gen.send(request)\n",
            "               ^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/TTS_infer_pack/TTS.py\", line 1337, in run\n",
            "    raise e\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/TTS_infer_pack/TTS.py\", line 1176, in run\n",
            "    item = make_batch(item)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/TTS_infer_pack/TTS.py\", line 1141, in make_batch\n",
            "    phones, bert_features, norm_text = self.text_preprocessor.segment_and_extract_feature_for_text(\n",
            "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/TTS_infer_pack/TextPreprocessor.py\", line 120, in segment_and_extract_feature_for_text\n",
            "    return self.get_phones_and_bert(text, language, version)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/TTS_infer_pack/TextPreprocessor.py\", line 179, in get_phones_and_bert\n",
            "    phones, word2ph, norm_text = self.clean_text_inf(textlist[i], lang, version)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/TTS_infer_pack/TextPreprocessor.py\", line 210, in clean_text_inf\n",
            "    phones, word2ph, norm_text = clean_text(text, language, version)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/text/cleaner.py\", line 47, in clean_text\n",
            "    phones = language_module.g2p(norm_text)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/text/english.py\", line 365, in g2p\n",
            "    phone_list = _g2p(text)\n",
            "                 ^^^^^^^^^^\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/text/english.py\", line 273, in __call__\n",
            "    tokens = pos_tag(words)  # tuples of (word, tag)\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nltk/tag/__init__.py\", line 168, in pos_tag\n",
            "    tagger = _get_tagger(lang)\n",
            "             ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nltk/tag/__init__.py\", line 110, in _get_tagger\n",
            "    tagger = PerceptronTagger()\n",
            "             ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nltk/tag/perceptron.py\", line 183, in __init__\n",
            "    self.load_from_json(lang)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nltk/tag/perceptron.py\", line 273, in load_from_json\n",
            "    loc = find(f\"taggers/averaged_perceptron_tagger_{lang}/\")\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nltk/data.py\", line 579, in find\n",
            "    raise LookupError(resource_not_found)\n",
            "LookupError: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "INFO:pyngrok.process.ngrok:t=2025-06-11T06:53:26+0000 lvl=info msg=\"join connections\" obj=join id=02da8310e77c l=127.0.0.1:9880 r=[2001:b400:e453:7df1:4d35:40fc:8719:d037]:52252\n",
            "\u001b[32mINFO\u001b[0m:     2001:b400:e453:7df1:4d35:40fc:8719:d037:0 - \"\u001b[1mGET /tts?text=%E6%93%81%E6%9C%89%E7%8E%BB%E7%92%83%E7%9A%84%E5%85%89%E5%AD%B8%E5%93%81%E8%B3%AA%E5%92%8C%E6%B5%81%E5%8B%95%E6%80%A7%EF%BC%8C%E5%8F%AA%E6%9C%89%E8%98%8B%E6%9E%9C%E6%89%8D%E8%83%BD%E5%AF%A6%E7%8F%BE%E3%80%82%E5%AE%83%E6%9C%83%E6%A0%B9%E6%93%9A%E4%BD%A0%E7%9A%84%E5%85%A7%E5%AE%B9%EF%BC%8C%E7%94%9A%E8%87%B3%E6%96%87%E6%9C%AC%E9%80%B2%E8%A1%8C%E8%BD%89%E6%8F%9B%EF%BC%8C%E4%B8%A6%E4%BD%BF%E7%80%8F%E8%A6%BD%E5%92%8C%E6%8E%A7%E5%88%B6%E6%9B%B4%E5%8A%A0%E6%B8%85%E6%99%B0%E3%80%82&text_lang=zh&ref_audio_path=badXT_71.wav&prompt_lang=zh&prompt_text=%E5%9D%8F%E5%A5%B3%E4%BA%BA%E5%94%B1%E8%AE%B0%E5%BD%95%E8%B6%85%E8%BF%87%E4%B8%89%E5%8D%81%E5%88%86%E9%92%9F%EF%BC%8C%E9%82%A3%E6%98%AF%E5%9B%A0%E4%B8%BA%E4%BB%A5%E5%89%8D%E7%9C%8B%E5%88%B0%E5%B0%8F%E6%96%B0%E5%B0%B1%E7%83%A6%E4%BA%86%EF%BC%8C%E6%A0%B9%E6%9C%AC%E4%B8%8D%E6%83%B3%E8%B7%9F%E5%B0%8F%E6%96%B0%E8%A7%81%E9%9D%A2%E3%80%82%E4%BD%86%E6%98%AF%E6%88%91%E4%B8%8D%E7%9F%A5%E9%81%93%E4%B8%BA%E4%BB%80%E4%B9%88%EF%BC%8C%E6%88%91%E5%AF%B9%E4%BD%A0%E4%BB%AC%E6%9C%89%E4%B8%80%E7%A7%8D%E7%89%B9%E5%88%AB%E7%9A%84%E6%84%9F%E8%A7%89%E3%80%82&text_split_method=cut5&batch_size=1&media_type=wav&streaming_mode=true HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "Set seed to 1987755200\n",
            "Parallel Inference Mode Enabled\n",
            "Segmented Return Mode Enabled\n",
            "Segmented Return Mode does not support Bucket Processing, Bucket Processing Disabled automatically\n",
            "Bucket Processing Mode Disabled\n",
            "Actual Input Reference Text: 坏女人唱记录超过三十分钟，那是因为以前看到小新就烦了，根本不想跟小新见面。但是我不知道为什么，我对你们有一种特别的感觉。\n",
            "############ Segment Text ############\n",
            "Actual Input Target Text:\n",
            "擁有玻璃的光學品質和流動性，只有蘋果才能實現。它會根據你的內容，甚至文本進行轉換，並使瀏覽和控制更加清晰。\n",
            "Actual Input Target Text (after sentence segmentation):\n",
            "['擁有玻璃的光學品質和流動性，', '只有蘋果才能實現。', '它會根據你的內容，', '甚至文本進行轉換，', '並使瀏覽和控制更加清晰。']\n",
            "############ 推理 ############\n",
            "############ Extract Text BERT Features ############\n",
            "100% 1/1 [00:00<00:00, 22.18it/s]\n",
            "Processed text from the frontend (per sentence): ['拥有玻璃的光学品质和流动性,']\n",
            "############ Predict Semantic Token ############\n",
            "  2% 26/1500 [00:00<00:17, 85.41it/s]INFO:pyngrok.process.ngrok:t=2025-06-11T06:53:26+0000 lvl=info msg=\"join connections\" obj=join id=bc15e94e271e l=127.0.0.1:9880 r=[2001:b400:e453:7df1:4d35:40fc:8719:d037]:52252\n",
            "\u001b[32mINFO\u001b[0m:     2001:b400:e453:7df1:4d35:40fc:8719:d037:0 - \"\u001b[1mGET /tts?text=%E6%93%81%E6%9C%89%E7%8E%BB%E7%92%83%E7%9A%84%E5%85%89%E5%AD%B8%E5%93%81%E8%B3%AA%E5%92%8C%E6%B5%81%E5%8B%95%E6%80%A7%EF%BC%8C%E5%8F%AA%E6%9C%89%E8%98%8B%E6%9E%9C%E6%89%8D%E8%83%BD%E5%AF%A6%E7%8F%BE%E3%80%82%E5%AE%83%E6%9C%83%E6%A0%B9%E6%93%9A%E4%BD%A0%E7%9A%84%E5%85%A7%E5%AE%B9%EF%BC%8C%E7%94%9A%E8%87%B3%E6%96%87%E6%9C%AC%E9%80%B2%E8%A1%8C%E8%BD%89%E6%8F%9B%EF%BC%8C%E4%B8%A6%E4%BD%BF%E7%80%8F%E8%A6%BD%E5%92%8C%E6%8E%A7%E5%88%B6%E6%9B%B4%E5%8A%A0%E6%B8%85%E6%99%B0%E3%80%82&text_lang=zh&ref_audio_path=badXT_71.wav&prompt_lang=zh&prompt_text=%E5%9D%8F%E5%A5%B3%E4%BA%BA%E5%94%B1%E8%AE%B0%E5%BD%95%E8%B6%85%E8%BF%87%E4%B8%89%E5%8D%81%E5%88%86%E9%92%9F%EF%BC%8C%E9%82%A3%E6%98%AF%E5%9B%A0%E4%B8%BA%E4%BB%A5%E5%89%8D%E7%9C%8B%E5%88%B0%E5%B0%8F%E6%96%B0%E5%B0%B1%E7%83%A6%E4%BA%86%EF%BC%8C%E6%A0%B9%E6%9C%AC%E4%B8%8D%E6%83%B3%E8%B7%9F%E5%B0%8F%E6%96%B0%E8%A7%81%E9%9D%A2%E3%80%82%E4%BD%86%E6%98%AF%E6%88%91%E4%B8%8D%E7%9F%A5%E9%81%93%E4%B8%BA%E4%BB%80%E4%B9%88%EF%BC%8C%E6%88%91%E5%AF%B9%E4%BD%A0%E4%BB%AC%E6%9C%89%E4%B8%80%E7%A7%8D%E7%89%B9%E5%88%AB%E7%9A%84%E6%84%9F%E8%A7%89%E3%80%82&text_split_method=cut5&batch_size=1&media_type=wav&streaming_mode=true HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "Set seed to 3449280586\n",
            "Parallel Inference Mode Enabled\n",
            "Segmented Return Mode Enabled\n",
            "Segmented Return Mode does not support Bucket Processing, Bucket Processing Disabled automatically\n",
            "Bucket Processing Mode Disabled\n",
            "Actual Input Reference Text: 坏女人唱记录超过三十分钟，那是因为以前看到小新就烦了，根本不想跟小新见面。但是我不知道为什么，我对你们有一种特别的感觉。\n",
            "############ Segment Text ############\n",
            "Actual Input Target Text:\n",
            "擁有玻璃的光學品質和流動性，只有蘋果才能實現。它會根據你的內容，甚至文本進行轉換，並使瀏覽和控制更加清晰。\n",
            "Actual Input Target Text (after sentence segmentation):\n",
            "['擁有玻璃的光學品質和流動性，', '只有蘋果才能實現。', '它會根據你的內容，', '甚至文本進行轉換，', '並使瀏覽和控制更加清晰。']\n",
            "############ 推理 ############\n",
            "############ Extract Text BERT Features ############\n",
            "\n",
            "100% 1/1 [00:00<00:00, 17.42it/s]\n",
            "Processed text from the frontend (per sentence): ['拥有玻璃的光学品质和流动性,']\n",
            "############ Predict Semantic Token ############\n",
            "\n",
            "  2% 35/1500 [00:00<00:21, 67.29it/s]\n",
            "  0% 4/1500 [00:00<00:37, 39.53it/s]\u001b[A\n",
            "  3% 43/1500 [00:00<00:27, 52.08it/s]\n",
            "  1% 12/1500 [00:00<00:38, 38.41it/s]\u001b[A\n",
            "  3% 49/1500 [00:00<00:32, 45.03it/s]\n",
            "  4% 55/1500 [00:01<00:34, 42.34it/s]\n",
            "  4% 60/1500 [00:01<00:34, 41.95it/s]\n",
            "  4% 65/1500 [00:01<00:35, 40.91it/s]\n",
            "  2% 32/1500 [00:00<00:40, 36.04it/s]\u001b[AT2S Decoding EOS [240 -> 306]\n",
            "  4% 65/1500 [00:01<00:29, 48.74it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "\n",
            "  2% 37/1500 [00:01<00:40, 36.52it/s]\u001b[A\n",
            "  3% 42/1500 [00:01<00:37, 39.18it/s]\u001b[A0.000\t0.001\t1.386\t0.268\n",
            "\n",
            "  3% 49/1500 [00:01<00:30, 47.24it/s]\u001b[A\n",
            "  4% 57/1500 [00:01<00:25, 56.39it/s]\u001b[AT2S Decoding EOS [240 -> 306]\n",
            "  4% 65/1500 [00:01<00:31, 45.43it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "0.000\t0.000\t1.491\t0.171\n",
            "############ Extract Text BERT Features ############\n",
            "100% 1/1 [00:00<00:00, 38.88it/s]\n",
            "Processed text from the frontend (per sentence): ['只有苹果才能实现.']\n",
            "############ Predict Semantic Token ############\n",
            "  3% 45/1500 [00:00<00:16, 87.97it/s]T2S Decoding EOS [240 -> 288]\n",
            "  3% 47/1500 [00:00<00:17, 84.97it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "0.000\t0.000\t0.582\t0.147\n",
            "############ Extract Text BERT Features ############\n",
            "100% 1/1 [00:00<00:00, 33.44it/s]\n",
            "Processed text from the frontend (per sentence): ['它会根据你的内容,']\n",
            "############ Predict Semantic Token ############\n",
            "  2% 35/1500 [00:00<00:17, 81.89it/s]T2S Decoding EOS [240 -> 279]\n",
            "  3% 38/1500 [00:00<00:18, 78.65it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "0.000\t0.000\t0.516\t0.141\n",
            "############ Extract Text BERT Features ############\n",
            "100% 1/1 [00:00<00:00, 34.38it/s]\n",
            "Processed text from the frontend (per sentence): ['甚至文本进行转换,']\n",
            "############ Predict Semantic Token ############\n",
            "  3% 44/1500 [00:00<00:18, 76.83it/s]T2S Decoding EOS [240 -> 285]\n",
            "  3% 44/1500 [00:00<00:18, 77.20it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "0.000\t0.000\t0.602\t0.148\n",
            "############ Extract Text BERT Features ############\n",
            "100% 1/1 [00:00<00:00, 36.82it/s]\n",
            "Processed text from the frontend (per sentence): ['并使浏览和控制更加清晰.']\n",
            "############ Predict Semantic Token ############\n",
            "  4% 62/1500 [00:00<00:18, 79.86it/s]T2S Decoding EOS [240 -> 306]\n",
            "  4% 65/1500 [00:00<00:18, 77.82it/s]\n",
            "############ Synthesize Audio ############\n",
            "Parallel Synthesis in Progress...\n",
            "0.000\t0.000\t0.865\t0.074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's/is_share=False/is_share=True/g' config.py\n",
        "!python webui.py"
      ],
      "metadata": {
        "id": "s5xoT-62aXe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f90e004a-462b-43f8-c39d-3b0deff2543d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Running on local URL:  http://0.0.0.0:9874\n",
            "* Running on public URL: https://ca909823d060272d32.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 3090, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/webui.py\", line 1973, in <module>\n",
            "    app.queue().launch(  # concurrency_count=511, max_size=1022\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2996, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 3094, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/http_server.py\", line 69, in close\n",
            "    self.thread.join(timeout=5)\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1123, in join\n",
            "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 0.0.0.0:9874 <> https://ca909823d060272d32.gradio.live\n",
            "^C\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}